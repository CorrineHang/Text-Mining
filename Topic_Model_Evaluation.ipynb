{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SESSION 7. TOPIC MODELS: EVALUATION AND ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get modules ready and available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "!{sys.executable} -m pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We use the text normalization function we used last time. The function is defined in Text_Normalization_Function.ipynb notebook.\n",
    "We will run that notebook (to make function available) using the line below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Text_Normalization_Function.ipynb file should be in the same folder as the notebook you are using right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html.parser\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/ae/4b752c60868d26d6d14e89882ade7204fd73543e1bde64b6e9b01c1d9856/html-parser-0.2.tar.gz\n",
      "Requirement already satisfied: ply in /anaconda3/lib/python3.6/site-packages (from html.parser) (3.11)\n",
      "Building wheels for collected packages: html.parser\n",
      "  Building wheel for html.parser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/corrine/Library/Caches/pip/wheels/f5/5e/9f/dbce0d6a89f44b3f30fba0a9b1b24a288882ea2e235e515d7b\n",
      "Successfully built html.parser\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "Requirement already satisfied: pattern3 in /anaconda3/lib/python3.6/site-packages (3.0.0)\n",
      "Requirement already satisfied: docx in /anaconda3/lib/python3.6/site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.6/site-packages (from pattern3) (4.6.0)\n",
      "Requirement already satisfied: simplejson in /anaconda3/lib/python3.6/site-packages (from pattern3) (3.16.0)\n",
      "Requirement already satisfied: pdfminer.six in /anaconda3/lib/python3.6/site-packages (from pattern3) (20181108)\n",
      "Requirement already satisfied: cherrypy in /anaconda3/lib/python3.6/site-packages (from pattern3) (18.1.1)\n",
      "Requirement already satisfied: pdfminer3k in /anaconda3/lib/python3.6/site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: feedparser in /anaconda3/lib/python3.6/site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (5.1.0)\n",
      "Requirement already satisfied: lxml in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (4.2.1)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.11.0)\n",
      "Requirement already satisfied: pycryptodome in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (3.8.1)\n",
      "Requirement already satisfied: sortedcontainers in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.5.10)\n",
      "Requirement already satisfied: more-itertools in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (4.1.0)\n",
      "Requirement already satisfied: cheroot>=6.2.4 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (6.5.4)\n",
      "Requirement already satisfied: zc.lockfile in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (1.4)\n",
      "Requirement already satisfied: portend>=2.1.1 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (2.3)\n",
      "Requirement already satisfied: ply>=3.4 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: pytest>=2.0 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.5.1)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /anaconda3/lib/python3.6/site-packages (from cheroot>=6.2.4->cherrypy->pattern3) (1.5)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from zc.lockfile->cherrypy->pattern3) (39.1.0)\n",
      "Requirement already satisfied: tempora>=1.8 in /anaconda3/lib/python3.6/site-packages (from portend>=2.1.1->cherrypy->pattern3) (1.14)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (18.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: jaraco.functools>=1.20 in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2018.4)\n",
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the text normalization function is working properly by running it on the test corpus below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed corpus:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "test_text = \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"\n",
    "test_corpus = [test_text]\n",
    "test_corpus.append(test_text)\n",
    "normalized_test_corpus = normalize_corpus(test_corpus)\n",
    "\n",
    "print(\"Original corpus:  \", test_corpus,\"\\n\")\n",
    "print(\"Processed corpus: \", normalize_corpus(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for getting keywords (words with highest weights) from the estimated topic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_words(vectorizer, lda_model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** TOPIC MODELING: NEWS ****\n",
    "\n",
    "The dataset here is the one we used for doing classification. \n",
    "The newspaper blogposts have 4 topics: atheism, religion, computer graphics and space sciene. \n",
    "Of course, we will not use this information for topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data and set up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "dataset = fetch_20newsgroups(shuffle=True, \n",
    "                             random_state=1, \n",
    "                             categories = categories, \n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "news_corpus = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the corpus and create \"bag-of-words\" representation of the data. We'll limit the number of features to 1000. \n",
    "\n",
    "NOTE: It will take a couple of minutes to get the data ready! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_corpus_news = normalize_corpus(news_corpus)\n",
    "bow_vectorizer_news = CountVectorizer()\n",
    "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)\n",
    "bow_feature_names_news = bow_vectorizer_news.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics_news = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the topic model (LDA). NOTE: It will take a couple of minutes for the estimation to finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_news_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>space</td>\n",
       "      <td>image</td>\n",
       "      <td>use</td>\n",
       "      <td>file</td>\n",
       "      <td>program</td>\n",
       "      <td>system</td>\n",
       "      <td>data</td>\n",
       "      <td>nasa</td>\n",
       "      <td>launch</td>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>people</td>\n",
       "      <td>think</td>\n",
       "      <td>god</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>good</td>\n",
       "      <td>use</td>\n",
       "      <td>believe</td>\n",
       "      <td>thing</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>jesus</td>\n",
       "      <td>matthew</td>\n",
       "      <td>god</td>\n",
       "      <td>ra</td>\n",
       "      <td>word</td>\n",
       "      <td>christian</td>\n",
       "      <td>men</td>\n",
       "      <td>day</td>\n",
       "      <td>greek</td>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_0   word_1 word_2 word_3   word_4     word_5 word_6   word_7  \\\n",
       "Topic_0   space    image    use   file  program     system   data     nasa   \n",
       "Topic_1  people    think    god   know     like       good    use  believe   \n",
       "Topic_2   jesus  matthew    god     ra     word  christian    men      day   \n",
       "\n",
       "         word_8 word_9  \n",
       "Topic_0  launch    edu  \n",
       "Topic_1   thing   even  \n",
       "Topic_2   greek   john  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words_news = 10\n",
    "topic_words = get_topic_words(vectorizer = bow_vectorizer_news, \n",
    "                              lda_model = lda_news, \n",
    "                              n_words = no_top_words_news)\n",
    "pd.DataFrame(topic_words, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_top_words_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_words))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a word vectors (words are in alphabetical order) for each topic. Each column is a topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000062david42</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000100255pixel</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000usd</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001200201pixel</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00index</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01a</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>023b</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04g</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>054589e</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Topic_0   Topic_1   Topic_2\n",
       "000062david42   0.000013  0.000004  0.000014\n",
       "000100255pixel  0.000013  0.000004  0.000014\n",
       "000usd          0.000023  0.000004  0.000014\n",
       "001200201pixel  0.000013  0.000004  0.000014\n",
       "00index         0.000013  0.000004  0.000014\n",
       "00pm            0.000022  0.000004  0.000015\n",
       "01a             0.000013  0.000004  0.000014\n",
       "023b            0.000025  0.000004  0.000014\n",
       "04g             0.000013  0.000004  0.000014\n",
       "054589e         0.000013  0.000004  0.000014"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
    "word_weights_df = pd.DataFrame(word_weights.T, \n",
    "                               index = bow_feature_names_news, \n",
    "                               columns = [\"Topic_\" + str(i) for i in range(no_topics_news)])\n",
    "word_weights_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sort by word weights in Topic 0 (descending order) and see the weights by 10 most frequent words in Topic 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasa</th>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launch</th>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu</th>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic_0   Topic_1   Topic_2\n",
       "space    0.010149  0.000285  0.000016\n",
       "image    0.008256  0.000194  0.000018\n",
       "use      0.006876  0.004251  0.000029\n",
       "file     0.005271  0.000170  0.000015\n",
       "program  0.005198  0.000125  0.000014\n",
       "system   0.004487  0.001968  0.000015\n",
       "data     0.004383  0.000068  0.000030\n",
       "nasa     0.004080  0.000054  0.000014\n",
       "launch   0.003944  0.000031  0.000014\n",
       "edu      0.003907  0.000265  0.000847"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sort by word weights in Topic 1 (descending order) and see the weights by 10 most frequent words in Topic 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believe</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic_0   Topic_1   Topic_2\n",
       "people   0.000416  0.007939  0.000026\n",
       "think    0.000479  0.007441  0.000100\n",
       "god      0.000013  0.007198  0.004349\n",
       "know     0.002233  0.006194  0.000448\n",
       "like     0.001948  0.005216  0.000126\n",
       "good     0.001758  0.004366  0.000504\n",
       "use      0.006876  0.004251  0.000029\n",
       "believe  0.000136  0.004238  0.000039\n",
       "thing    0.000673  0.004225  0.000955\n",
       "even     0.000537  0.004203  0.000212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights_df.sort_values(by='Topic_1',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign a dominant topic to each document in our corpus. \n",
    "\n",
    "To do this, we need each document be represented as a bag-of-words. \n",
    "Each word in the document is associated with some topic. Word weights in a word vector for a topic provide a measure for that association.\n",
    "E.g., if you sum weights for Topic 0 across all words and their frequencies in a document, you'll get a measure of associaton of that document with Topic 0.\n",
    "\n",
    "The attribute .transform does that for you in Python (normalized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_news_output = lda_news.transform(bow_news_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a nice-looking dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc_0</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.5637</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_1</th>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_2</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_3</th>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic_0  Topic_1  Topic_2  dominant_topic\n",
       "Doc_0   0.0004   0.4359   0.5637               2\n",
       "Doc_1   0.8054   0.1928   0.0018               0\n",
       "Doc_2   0.0094   0.9461   0.0445               1\n",
       "Doc_3   0.9879   0.0060   0.0061               0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
    "topic_names = [\"Topic_\" + str(i) for i in range(no_topics_news)]\n",
    "df_document_topic = pd.DataFrame(np.round(lda_news_output, 4), columns=topic_names, index=doc_names)\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "df_document_topic[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** INTERACTIVE TOPIC VISUALIZATION ****\n",
    "\n",
    "You can visualize the topics: topic size, ferquency of words in a topic versus the whole corpus, etc. You can rank words (terms) in a topic by relevancy: do you want rare and exclusive terms (i.e. found mostly in that topic) OR terms that are used frequently in that topic, not not nessesarily exclisuve to that topic?\n",
    "\n",
    "Relevancy weight parameter is λ (0 ≤ λ ≤ 1): you can adjust it!\n",
    "\n",
    "* small λ highlights potentially rare, but exclusive terms for the selected topic;\n",
    "* large values of λ (near 1) highlight frequent, but not necessarily exclusive, terms for the selected topic;\n",
    "\n",
    "Relevancy is measured as: \n",
    "\n",
    "    Relevancy = λ log[p(term | topic)] + (1 - λ) log[p(term | topic)/p(term)], \n",
    "   \n",
    "   where p(term | topic) stands for term (word) weight, i.e. frequency, in a topic and p(term) stands for term's weight (frequency) in a corpus.\n",
    "\n",
    "Additional information on how to use this visualization:\n",
    "* http://www.kennyshirley.com/LDAvis/\n",
    "* https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el344674588853672542259637\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el344674588853672542259637_data = {\"mdsDat\": {\"x\": [-372.1424560546875, -437.7695617675781, -620.1272583007812], \"y\": [-195.24327087402344, -443.70355224609375, -262.63836669921875], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [47.154760630975275, 44.18198026467611, 8.66325910434861]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [315.0, 975.0, 707.0, 790.0, 735.0, 699.0, 497.0, 508.0, 325.0, 416.0, 387.0, 372.0, 239.0, 385.0, 89.0, 266.0, 257.0, 278.0, 234.0, 261.0, 277.0, 235.0, 228.0, 243.0, 274.0, 239.0, 294.0, 236.0, 68.0, 403.0, 260.8233001784522, 265.62142202033715, 242.58990794050212, 238.67780379182733, 236.1182745177928, 187.34593716577595, 182.78182656022722, 182.6662092133982, 171.9974193478104, 168.93664132210284, 144.49700684053303, 134.84202549452854, 134.33084477914846, 127.30889931859882, 125.26452727251748, 113.72865398244842, 113.53482675945553, 106.36149765444091, 108.18627541645317, 161.7968118568294, 102.47282234372057, 103.83366469209604, 86.73469275389162, 99.88508365051757, 82.73108325983394, 83.26903915525425, 74.46843809212922, 75.92433282500349, 369.19578826587843, 69.75235669839026, 382.01257383559584, 228.21882802390954, 271.73704615109773, 274.212670730545, 410.30015495241435, 772.9219604775254, 950.1173150781806, 486.67098620102064, 493.4392840018756, 171.09649517712802, 284.19227269357395, 219.52675386773416, 157.30520453851108, 365.81096064144594, 187.8542653256351, 221.25980663844751, 205.21599467017845, 240.49531233296705, 643.7716449193315, 420.11505997791534, 257.0746202123366, 240.1035930712542, 209.84447746849384, 206.43397658493063, 222.4142062168245, 193.21363986772522, 202.1041842137027, 209.01509600793457, 234.9276287772482, 227.46432676432872, 191.26320528550772, 184.09529436644186, 180.46602897770018, 159.65647860817913, 186.1062905058519, 145.03435851752877, 127.36594370561836, 113.2933506310888, 112.81016872440858, 109.17734852188705, 101.01963365507292, 81.62138405333639, 85.63723914135791, 77.97200740301898, 63.24946737520329, 69.17333858389416, 63.92877035257462, 59.09799606488042, 60.504801170997546, 56.91204702671978, 57.088134191531765, 54.42499584244987, 53.5724679460866, 62.91017577131232, 44.80597788098111, 47.15478075643817, 47.904514640352595, 44.663537822008145, 274.6268262611153, 139.59455966724755, 128.94561991106465, 371.76154913692983, 696.3994305632816, 108.66673300922835, 97.64528269234985, 652.7434328648694, 141.2094182438372, 200.5526449196463, 158.65922806301418, 186.54754439834815, 631.3986238545208, 252.49492699203734, 144.6157511670352, 236.46737503158178, 368.63888140835235, 250.8183465599017, 232.21663165504964, 265.00736316736703, 189.4449757725964, 370.6008030049971, 210.48746231491512, 203.44107916825774, 325.8899289327295, 279.96146692570153, 543.301698444806, 272.9002618328293, 278.77625051667974, 457.5366796364103, 363.5052819263949, 338.3428967843854, 231.0900580881098, 382.9874520782865, 331.88435841557583, 302.3153140836174, 321.3928004027834, 337.81913628002764, 367.04908186222394, 239.72726152549996, 372.8506881526991, 254.25236151433631, 241.9209472977535, 43.000930099000314, 38.30112041084697, 37.57267434909489, 42.156458667801886, 36.90439494194462, 34.71942010127406, 26.491358925313055, 26.662230790190314, 23.454620191141302, 21.636445676357766, 24.64931637668575, 20.43226655241128, 18.558955048617534, 18.35718098575078, 16.814997553344718, 86.47625591200058, 15.438461133365385, 13.960838846875827, 14.850297803332985, 14.63147542937454, 14.065005995622123, 16.592127550150146, 13.130993336403757, 12.52019275407436, 12.437978825896389, 12.513740071895116, 12.463636713288402, 11.729114091183634, 11.729114089298472, 11.72911408713657, 12.416425732478253, 63.60988505365133, 44.787006195101235, 214.3274450785668, 39.248122614271956, 29.83506196963311, 49.88166340385168, 33.55524781660765, 22.7581373131763, 40.80774976257426, 24.22792412018827, 43.02440958656985, 25.706659066167475, 28.35427930606887, 31.365024744280642, 43.77119003929011, 62.43159384346651, 35.79070555754264, 36.444203304456174, 27.271642253993036, 74.80919127783, 49.4507727714482, 52.457795006333996, 29.269166972614844, 38.449821605623065, 30.701689666304198, 30.62382108712571, 29.63319863869949, 29.141227787006724], \"Term\": [\"jesus\", \"space\", \"god\", \"image\", \"people\", \"think\", \"program\", \"file\", \"christian\", \"data\", \"nasa\", \"launch\", \"word\", \"believe\", \"matthew\", \"satellite\", \"bible\", \"religion\", \"day\", \"format\", \"software\", \"atheist\", \"argument\", \"jpeg\", \"graphic\", \"ftp\", \"available\", \"orbit\", \"ra\", \"edu\", \"format\", \"satellite\", \"jpeg\", \"ftp\", \"orbit\", \"shuttle\", \"gif\", \"pub\", \"package\", \"lunar\", \"rocket\", \"graphics\", \"3d\", \"flight\", \"commercial\", \"directory\", \"probe\", \"pc\", \"spacecraft\", \"technology\", \"solar\", \"dc\", \"processing\", \"vehicle\", \"unix\", \"hardware\", \"pixel\", \"fax\", \"launch\", \"sgi\", \"nasa\", \"color\", \"graphic\", \"software\", \"data\", \"image\", \"space\", \"program\", \"file\", \"display\", \"available\", \"mission\", \"user\", \"edu\", \"center\", \"send\", \"mail\", \"information\", \"use\", \"system\", \"include\", \"work\", \"need\", \"new\", \"time\", \"earth\", \"year\", \"know\", \"atheist\", \"argument\", \"belief\", \"atheism\", \"evidence\", \"moral\", \"reason\", \"religious\", \"statement\", \"morality\", \"islam\", \"truth\", \"conclusion\", \"muslim\", \"existence\", \"war\", \"fallacy\", \"definition\", \"false\", \"islamic\", \"argue\", \"homosexual\", \"sex\", \"premise\", \"tyre\", \"perfect\", \"homosexuality\", \"thread\", \"doubt\", \"innocent\", \"religion\", \"agree\", \"yes\", \"believe\", \"people\", \"universe\", \"theory\", \"think\", \"wrong\", \"claim\", \"anything\", \"law\", \"god\", \"life\", \"nothing\", \"true\", \"even\", \"something\", \"bible\", \"seem\", \"fact\", \"thing\", \"really\", \"exist\", \"way\", \"mean\", \"know\", \"christian\", \"us\", \"like\", \"well\", \"take\", \"right\", \"good\", \"point\", \"give\", \"many\", \"could\", \"time\", \"question\", \"use\", \"may\", \"much\", \"juda\", \"p2\", \"den\", \"prophet\", \"p3\", \"p1\", \"magi\", \"psalm\", \"zoroastrian\", \"muhammad\", \"messiah\", \"luke\", \"ye\", \"isaiah\", \"het\", \"matthew\", \"prophethood\", \"een\", \"disciple\", \"hebrew\", \"hanging\", \"db\", \"ico\", \"p4\", \"bobbe\", \"archer\", \"manhattan\", \"p13\", \"p12\", \"p23\", \"caligiuri\", \"ra\", \"greek\", \"jesus\", \"lord\", \"hang\", \"men\", \"prophecy\", \"scholar\", \"passage\", \"van\", \"christ\", \"holy\", \"gd\", \"verse\", \"john\", \"word\", \"speak\", \"david\", \"king\", \"god\", \"day\", \"christian\", \"sin\", \"man\", \"de\", \"com\", \"love\", \"name\"], \"Total\": [315.0, 975.0, 707.0, 790.0, 735.0, 699.0, 497.0, 508.0, 325.0, 416.0, 387.0, 372.0, 239.0, 385.0, 89.0, 266.0, 257.0, 278.0, 234.0, 261.0, 277.0, 235.0, 228.0, 243.0, 274.0, 239.0, 294.0, 236.0, 68.0, 403.0, 261.3780821571307, 266.1872594181391, 243.14504880127316, 239.2329810652898, 236.71754864656864, 187.90974176294668, 183.33774652857045, 183.23245131594487, 172.5520435752403, 169.50941228094163, 145.08588098953345, 135.3998938264457, 134.89325070807348, 127.89750171779228, 125.86195994364877, 114.28455716515289, 114.0917129090808, 106.91826415184643, 108.7526535664024, 162.6825122553518, 103.0466544522694, 104.41689004641788, 87.28912031393806, 100.52439824014152, 83.28583521311984, 83.88948641451127, 75.02613923294906, 76.49885615578054, 372.17251443480234, 70.31929490392002, 387.0032694845479, 230.11235922038796, 274.55763159883827, 277.3638503650801, 416.77620038509264, 790.2649257405336, 975.3671735265447, 497.86388396103456, 508.5946376144923, 173.2871397241273, 294.1186744197521, 226.5400901532061, 160.33513540709384, 403.65652570549446, 199.10156817832777, 244.26281515749167, 226.25625342333407, 275.57736164467633, 1017.1192221509516, 592.9888697958996, 354.84532953506897, 387.4154822316277, 342.5753919023679, 344.1566600166556, 603.3048126170852, 260.726862427593, 409.3302752084214, 760.0174300424419, 235.49481442921126, 228.05876655993416, 191.84456179896492, 184.702613823055, 181.06342414522948, 160.22437219233746, 186.8334440993548, 145.61734020925795, 127.96313037806759, 113.85554450247116, 113.38326217529203, 109.83616515596327, 101.643639577339, 82.19642806667467, 86.25240899590665, 78.60839822077666, 63.80595344778293, 69.7922048865276, 64.50454259810458, 59.66675692238199, 61.09115985818081, 57.477223359787004, 57.662337460484196, 54.98581868332666, 54.1695465382052, 63.6345732128306, 45.36572144263657, 47.75278770500355, 48.51485562301857, 45.23546530324981, 278.33468948176863, 141.74178106729903, 131.51748034152342, 385.20176599567327, 735.7856175438733, 110.96922358018689, 99.68363018071224, 699.3138397089926, 145.9698407041295, 209.83222877000316, 164.93969745708426, 196.6051160674879, 707.4498281900036, 271.64748667352626, 151.90434131234366, 260.2547478342039, 422.59525677538727, 278.20219857549324, 257.71765380777896, 299.86704863725294, 205.69829679580823, 450.00737436599314, 233.6672822637395, 226.49355176940807, 403.5262471881924, 335.4232205002527, 760.0174300424419, 325.6801568920503, 334.528428696001, 642.1257901956516, 483.95791716913163, 444.79245285312146, 269.0559478457443, 556.2577257794883, 453.36137456012824, 398.70344614357754, 441.85471175863506, 482.8915992284945, 603.3048126170852, 313.7762153339663, 1017.1192221509516, 433.79058953239075, 374.1757447567034, 43.63258151447153, 38.93013265929613, 38.19279091804105, 42.862605574519186, 37.52499938345212, 35.34981407383484, 27.1157138524771, 27.31967088370142, 24.084388442801046, 22.319451893902134, 25.439699686709478, 21.12088990764471, 19.199178830510554, 19.002262039421254, 17.44720686009441, 89.8849834860933, 16.066047829755743, 14.580954991497947, 15.51076229061416, 15.28496570324137, 14.697070549486206, 17.340708080297723, 13.763186077617506, 13.142567755002382, 13.069343833907194, 13.149026922570505, 13.103640409418132, 12.349230628506266, 12.349230629032322, 12.349230629638008, 13.075405337516194, 68.9922169091505, 48.29056373648838, 315.79990845889193, 47.55648144742959, 36.493699771289585, 67.21682755564669, 45.64788671938598, 28.828547044158825, 63.64849699280974, 33.08735402845575, 79.55072463156199, 36.25952257942699, 43.49612962364921, 59.112287579665946, 115.02704595446875, 239.64282071022242, 84.83765535584209, 92.39095556077082, 45.954726185315494, 707.4498281900036, 234.04676214701806, 325.6801568920503, 56.616910729945786, 151.41506359687597, 72.912904764433, 154.52731284176252, 117.10224650148794, 208.78219895991393], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7496, 0.7496, 0.7494, 0.7494, 0.7492, 0.7487, 0.7487, 0.7486, 0.7485, 0.7484, 0.7477, 0.7476, 0.7476, 0.7471, 0.747, 0.7469, 0.7468, 0.7465, 0.7465, 0.7463, 0.7462, 0.7461, 0.7454, 0.7454, 0.7451, 0.7443, 0.7443, 0.7442, 0.7437, 0.7436, 0.7388, 0.7435, 0.7414, 0.7403, 0.7361, 0.7295, 0.7255, 0.729, 0.7215, 0.739, 0.7174, 0.7203, 0.7327, 0.6533, 0.6936, 0.6528, 0.6541, 0.6156, 0.2943, 0.4071, 0.4294, 0.2733, 0.2616, 0.2406, -0.2461, 0.4521, 0.046, -0.5392, 0.8144, 0.8142, 0.8138, 0.8136, 0.8135, 0.8133, 0.813, 0.8128, 0.8122, 0.8119, 0.8118, 0.8108, 0.8107, 0.8098, 0.8097, 0.8087, 0.8081, 0.8079, 0.8079, 0.8073, 0.8072, 0.807, 0.8068, 0.8066, 0.8058, 0.8054, 0.8044, 0.8043, 0.8042, 0.8041, 0.8034, 0.8016, 0.7971, 0.7813, 0.7618, 0.7959, 0.7962, 0.7479, 0.7837, 0.7716, 0.778, 0.7643, 0.7031, 0.7437, 0.7677, 0.721, 0.6803, 0.7132, 0.7127, 0.6933, 0.7345, 0.6227, 0.7124, 0.7095, 0.6032, 0.6361, 0.4812, 0.64, 0.6345, 0.4779, 0.5306, 0.5433, 0.6647, 0.4436, 0.505, 0.5401, 0.4985, 0.4596, 0.3199, 0.5477, -0.1867, 0.2826, 0.3807, 2.4315, 2.4298, 2.4297, 2.4295, 2.4294, 2.4281, 2.4228, 2.4217, 2.4196, 2.415, 2.4145, 2.4129, 2.4122, 2.4115, 2.4092, 2.4074, 2.4062, 2.4026, 2.4026, 2.4024, 2.4021, 2.402, 2.3991, 2.3976, 2.3966, 2.3966, 2.396, 2.3946, 2.3946, 2.3946, 2.3944, 2.3649, 2.3708, 2.0585, 2.2541, 2.2446, 2.1478, 2.1383, 2.2096, 2.0016, 2.1344, 1.8315, 2.1021, 2.0182, 1.8123, 1.4799, 1.101, 1.583, 1.5158, 1.9243, 0.1994, 0.8915, 0.6202, 1.7863, 1.0754, 1.5811, 0.8275, 1.0719, 0.4769], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.8832, -5.8649, -5.9556, -5.9719, -5.9827, -6.214, -6.2387, -6.2393, -6.2995, -6.3175, -6.4737, -6.5429, -6.5467, -6.6004, -6.6166, -6.7132, -6.7149, -6.7802, -6.7631, -6.3607, -6.8174, -6.8042, -6.9841, -6.843, -7.0314, -7.0249, -7.1366, -7.1173, -5.5357, -7.202, -5.5015, -6.0167, -5.8422, -5.8331, -5.4301, -4.7968, -4.5904, -5.2594, -5.2456, -6.3048, -5.7973, -6.0555, -6.3888, -5.5449, -6.2113, -6.0477, -6.1229, -5.9643, -4.9797, -5.4065, -5.8976, -5.9659, -6.1006, -6.117, -6.0425, -6.1832, -6.1382, -6.1046, -5.9226, -5.9549, -6.1282, -6.1664, -6.1863, -6.3089, -6.1556, -6.4049, -6.5348, -6.6519, -6.6562, -6.6889, -6.7666, -6.9798, -6.9318, -7.0255, -7.2348, -7.1453, -7.2241, -7.3027, -7.2792, -7.3404, -7.3373, -7.3851, -7.4008, -7.2402, -7.5795, -7.5284, -7.5127, -7.5827, -5.7665, -6.4431, -6.5225, -5.4636, -4.836, -6.6936, -6.8005, -4.9007, -6.4316, -6.0808, -6.3151, -6.1532, -4.9339, -5.8505, -6.4078, -5.9161, -5.4721, -5.8572, -5.9342, -5.8021, -6.1378, -5.4668, -6.0325, -6.0665, -5.5953, -5.7472, -5.0842, -5.7728, -5.7515, -5.256, -5.4861, -5.5578, -5.9391, -5.4339, -5.5771, -5.6704, -5.6092, -5.5594, -5.4764, -5.9024, -5.4607, -5.8436, -5.8933, -5.9914, -6.1072, -6.1264, -6.0113, -6.1443, -6.2054, -6.4758, -6.4694, -6.5976, -6.6783, -6.5479, -6.7355, -6.8317, -6.8426, -6.9304, -5.2928, -7.0158, -7.1164, -7.0546, -7.0695, -7.109, -6.9437, -7.1777, -7.2253, -7.2319, -7.2258, -7.2298, -7.2906, -7.2906, -7.2906, -7.2336, -5.5999, -5.9507, -4.3852, -6.0828, -6.357, -5.843, -6.2395, -6.6277, -6.0438, -6.5652, -5.9909, -6.5059, -6.4079, -6.307, -5.9737, -5.6186, -6.175, -6.1569, -6.4468, -5.4377, -5.8517, -5.7926, -6.3761, -6.1033, -6.3283, -6.3309, -6.3638, -6.3805]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 2, 2, 2, 2, 1, 2, 2, 1, 2, 3, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 3, 1, 3, 1, 2, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 3, 1, 3, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 3, 1, 2, 2, 3, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 2, 3, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1, 2, 3, 2, 1, 1, 1, 2, 2, 3, 3, 3, 3, 1, 1, 2, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.9933780919105687, 0.9877115903709999, 0.014110165576728569, 0.036376931039061366, 0.9639886725351262, 0.9886663155039482, 0.9985078060656823, 0.9953574836174697, 0.9961959724959382, 0.997898830891837, 0.9655966271447586, 0.0339998812374915, 0.995597676624006, 0.03374854724873203, 0.9657276597329475, 0.0025960420960563103, 0.9002099645569461, 0.09700538411173988, 0.9181792255604385, 0.9177535755292708, 0.9442416838807391, 0.05022562148301804, 0.005022562148301804, 0.4525414465642327, 0.5405356167295001, 0.8382457273578641, 0.15966585283006934, 0.03335998497958429, 0.9579081401280632, 0.009531424279881226, 0.9908203139216661, 0.004345703131235378, 0.004345703131235378, 0.7442050074200224, 0.058242131015480016, 0.2006117846088756, 0.9931515452005142, 0.9936676846675756, 0.2733532747533682, 0.6999500520199882, 0.02692115584692262, 0.9837413931533721, 0.014396215509561543, 0.0023993692515935903, 0.32470710815700227, 0.28141282706940196, 0.3896485297884027, 0.29481287998616784, 0.49135479997694637, 0.20935987129452496, 0.9803521241047342, 0.9960074462452142, 0.4663097720471732, 0.10971994636404075, 0.42516479216065794, 0.9886490921469581, 0.9949521647042039, 0.9975100995951564, 0.9670704584955678, 0.986801445694306, 0.01154153737654159, 0.9893876707163839, 0.7402382639172763, 0.24546761083267196, 0.011506294257781498, 0.906711465546903, 0.05697913581305675, 0.037160305965037006, 0.9601565883828118, 0.1183165196446476, 0.8731759149774992, 0.009465321571571808, 0.9941267865100325, 0.10154814483820794, 0.8962727566154876, 0.9970736006235069, 0.0777838234406132, 0.9188214143922434, 0.9873686795003777, 0.992178185011742, 0.9934789069948355, 0.96933778600648, 0.02949303608538986, 0.992982648560465, 0.9985535047391487, 0.9990261331683769, 0.3448582696848589, 0.6437354367450699, 0.9981577905534155, 0.2357642024647802, 0.7574552036634428, 0.007524389440365325, 0.0014135278010576104, 0.8919360424673521, 0.10601458507932078, 0.2966250936448284, 0.6885297628240563, 0.016179550562445185, 0.9906845364889537, 0.007284445121242307, 0.9970465720825581, 0.020707979419266945, 0.04141595883853389, 0.9318590738670125, 0.02740199010424047, 0.16441194062544284, 0.8220597031272142, 0.9525707829230925, 0.9893969262117522, 0.9813564708764155, 0.9743679969131752, 0.27578962128072315, 0.7170530153298802, 0.9916971744302999, 0.9919383748123787, 0.9445487350593448, 0.9781529899933809, 0.021511773389246407, 0.7242592155199861, 0.2479953734076217, 0.025363163189415856, 0.8708988233563647, 0.1270060784061365, 0.9947946748934426, 0.9472556458098512, 0.9966197640821138, 0.9888253198803926, 0.3198227652847698, 0.6776442749598094, 0.27819544294536247, 0.33905069608966054, 0.3825187340498734, 0.9994034474401668, 0.985502083706376, 0.39168985421464164, 0.5875347813219625, 0.27499369322138933, 0.7144572986565283, 0.010526074381679974, 0.9914756885268106, 0.008060777955502526, 0.010172675258936129, 0.951145136710528, 0.040690701035744514, 0.055218622427482385, 0.9276728567817041, 0.01472496598066197, 0.28343356205105197, 0.7132558869196802, 0.0031146545280335385, 0.16822102385441295, 0.8200774912902631, 0.7429404866190552, 0.2561863746962259, 0.9469297973453759, 0.9969947846902015, 0.9588536057524749, 0.906052305287833, 0.08839534685734957, 0.004419767342867478, 0.1386916169444668, 0.6076013694709974, 0.2509657830423685, 0.9157760458212132, 0.25800335939898944, 0.7264831435708387, 0.01357912417889418, 0.033375986551348144, 0.9567782811386467, 0.4011152021245209, 0.5855359847105075, 0.011526298911624164, 0.13415886930215107, 0.8347662978800511, 0.03279439027385915, 0.014877226973738557, 0.23803563157981691, 0.7438613486869279, 0.9827160032498657, 0.9711305396374517, 0.026485378353748684, 0.00441422972562478, 0.998599637562829, 0.992485701893485, 0.35277540527334034, 0.6467549096677906, 0.9856872876887532, 0.9976102603082054, 0.5508132425699757, 0.3113292240612906, 0.13890073073503736, 0.987071764300049, 0.012919787490838337, 0.613003750309797, 0.3853166430518724, 0.5985646187699245, 0.319621883809183, 0.08135829769688295, 0.032915451637547784, 0.9545480974888858, 0.013166180655019115, 0.9969687560103963, 0.9901042174336705, 0.9717204545349326, 0.9717204545763263, 0.9761076421846197, 0.9717204544872732, 0.9860093433157088, 0.9891522145702374, 0.9968007126209456, 0.07855645044634504, 0.2828032216068422, 0.6441628936600293, 0.9914115314242073, 0.05300456963291283, 0.9459277042181367, 0.9900278546583753, 0.9863229103424475, 0.2316033210854713, 0.7323076438131092, 0.03529193464159563, 0.9820714011915659, 0.9991961474962351, 0.9966877852257162, 0.9781790077348033, 0.02209439237183334, 0.26288183007831945, 0.7448318518885717, 0.9798751017826134, 0.9336459195782221, 0.9882988750097963, 0.998731385656441, 0.23583686839118265, 0.7648763299173491, 0.043483165701870746, 0.043483165701870746, 0.9276408683065759, 0.06419383943991588, 0.8987137521588224, 0.03423671436795514, 0.9955391064839998, 0.9880191380816473, 0.010778390597254335, 0.9957605309342225, 0.11150097308831716, 0.8585574927800421, 0.02973359282355124, 0.9925155984708686, 0.9992965124681459, 0.20812703431807905, 0.797820298219303, 0.11004877044666507, 0.8837249747989772, 0.006669622451313035, 0.9047631742781125, 0.06550321623732941, 0.028657657103831616, 0.9885135169739158, 0.9954593557236845, 0.9951586237391867, 0.0529877021074066, 0.4239016168592528, 0.5122144537049306, 0.9878720663826507, 0.01081611751513851, 0.9898429070033108, 0.09705171324400318, 0.902221482379437, 0.9739921803654444, 0.025631373167511694, 0.9930792165366076, 0.03536165618223222, 0.5422120614608941, 0.42433987418678665, 0.9924733759230333, 0.7082763630024953, 0.29174240666531354, 0.19784508355644065, 0.7599049800236015, 0.040468312545635585, 0.9958046366146565, 0.00614694220132504, 0.020063474778900855, 0.9831102641661418, 0.13999770579039844, 0.824430934099013, 0.035554972899148815, 0.06434879083577978, 0.9337724536836489, 0.0028599462593679906, 0.9842357327983876, 0.3679731958990726, 0.6083160490763949, 0.023205516858500076, 0.07300539243996429, 0.9068038218858722, 0.01921194537893797, 0.9923871599597824, 0.9968700764721073, 0.01802301517010066, 0.9822543267704859, 0.9965680212921151, 0.12853915037240607, 0.8340098361372394, 0.038860673368401835, 0.6331607799507533, 0.36672200453669407, 0.9791989734587752, 0.01871080841004029, 0.2720072445883654, 0.725352652235641, 0.9947833734961656, 0.4567578265958995, 0.5244256527582549, 0.9922603915796893, 0.17347074815521016, 0.8078780556942644, 0.019825228360595446, 0.2479554435268447, 0.7521315120314289, 0.16274220059844413, 0.575857017502187, 0.25871837018214194, 0.6194899558931642, 0.36395034908723395, 0.015487248897329105, 0.027402920909585123, 0.9659529620628756, 0.9896256588748459, 0.49348902887074825, 0.5008180738539771, 0.007329044983228934, 0.015207103989571712, 0.9808582073273754, 0.9549754628241276], \"Term\": [\"3d\", \"agree\", \"agree\", \"anything\", \"anything\", \"archer\", \"argue\", \"argument\", \"atheism\", \"atheist\", \"available\", \"available\", \"belief\", \"believe\", \"believe\", \"believe\", \"bible\", \"bible\", \"bobbe\", \"caligiuri\", \"center\", \"center\", \"center\", \"christ\", \"christ\", \"christian\", \"christian\", \"claim\", \"claim\", \"claim\", \"color\", \"color\", \"color\", \"com\", \"com\", \"com\", \"commercial\", \"conclusion\", \"could\", \"could\", \"could\", \"data\", \"data\", \"data\", \"david\", \"david\", \"david\", \"day\", \"day\", \"day\", \"db\", \"dc\", \"de\", \"de\", \"de\", \"definition\", \"den\", \"directory\", \"disciple\", \"display\", \"display\", \"doubt\", \"earth\", \"earth\", \"earth\", \"edu\", \"edu\", \"edu\", \"een\", \"even\", \"even\", \"even\", \"evidence\", \"exist\", \"exist\", \"existence\", \"fact\", \"fact\", \"fallacy\", \"false\", \"fax\", \"file\", \"file\", \"flight\", \"format\", \"ftp\", \"gd\", \"gd\", \"gif\", \"give\", \"give\", \"give\", \"god\", \"god\", \"god\", \"good\", \"good\", \"good\", \"graphic\", \"graphic\", \"graphics\", \"greek\", \"greek\", \"greek\", \"hang\", \"hang\", \"hang\", \"hanging\", \"hardware\", \"hebrew\", \"het\", \"holy\", \"holy\", \"homosexual\", \"homosexuality\", \"ico\", \"image\", \"image\", \"include\", \"include\", \"include\", \"information\", \"information\", \"innocent\", \"isaiah\", \"islam\", \"islamic\", \"jesus\", \"jesus\", \"john\", \"john\", \"john\", \"jpeg\", \"juda\", \"king\", \"king\", \"know\", \"know\", \"know\", \"launch\", \"launch\", \"law\", \"law\", \"law\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"lord\", \"lord\", \"love\", \"love\", \"luke\", \"lunar\", \"magi\", \"mail\", \"mail\", \"mail\", \"man\", \"man\", \"man\", \"manhattan\", \"many\", \"many\", \"many\", \"matthew\", \"matthew\", \"may\", \"may\", \"may\", \"mean\", \"mean\", \"mean\", \"men\", \"men\", \"men\", \"messiah\", \"mission\", \"mission\", \"mission\", \"moral\", \"morality\", \"much\", \"much\", \"muhammad\", \"muslim\", \"name\", \"name\", \"name\", \"nasa\", \"nasa\", \"need\", \"need\", \"new\", \"new\", \"new\", \"nothing\", \"nothing\", \"nothing\", \"orbit\", \"p1\", \"p12\", \"p13\", \"p2\", \"p23\", \"p3\", \"p4\", \"package\", \"passage\", \"passage\", \"passage\", \"pc\", \"people\", \"people\", \"perfect\", \"pixel\", \"point\", \"point\", \"point\", \"premise\", \"probe\", \"processing\", \"program\", \"program\", \"prophecy\", \"prophecy\", \"prophet\", \"prophethood\", \"psalm\", \"pub\", \"question\", \"question\", \"ra\", \"ra\", \"ra\", \"really\", \"really\", \"really\", \"reason\", \"religion\", \"religion\", \"religious\", \"right\", \"right\", \"right\", \"rocket\", \"satellite\", \"scholar\", \"scholar\", \"seem\", \"seem\", \"seem\", \"send\", \"send\", \"send\", \"sex\", \"sgi\", \"shuttle\", \"sin\", \"sin\", \"sin\", \"software\", \"software\", \"solar\", \"something\", \"something\", \"space\", \"space\", \"spacecraft\", \"speak\", \"speak\", \"speak\", \"statement\", \"system\", \"system\", \"take\", \"take\", \"take\", \"technology\", \"technology\", \"theory\", \"theory\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"thread\", \"time\", \"time\", \"time\", \"true\", \"true\", \"true\", \"truth\", \"tyre\", \"universe\", \"universe\", \"unix\", \"us\", \"us\", \"us\", \"use\", \"use\", \"user\", \"user\", \"van\", \"van\", \"vehicle\", \"verse\", \"verse\", \"war\", \"way\", \"way\", \"way\", \"well\", \"well\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"wrong\", \"wrong\", \"ye\", \"year\", \"year\", \"year\", \"yes\", \"yes\", \"zoroastrian\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el344674588853672542259637\", ldavis_el344674588853672542259637_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el344674588853672542259637\", ldavis_el344674588853672542259637_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el344674588853672542259637\", ldavis_el344674588853672542259637_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "0     -372.142456 -195.243271       1        1  47.154761\n",
       "1     -437.769562 -443.703552       2        1  44.181980\n",
       "2     -620.127258 -262.638367       3        1   8.663259, topic_info=      Category        Freq       Term       Total  loglift  logprob\n",
       "term                                                               \n",
       "10046  Default  315.000000      jesus  315.000000  30.0000  30.0000\n",
       "17412  Default  975.000000      space  975.000000  29.0000  29.0000\n",
       "7939   Default  707.000000        god  707.000000  28.0000  28.0000\n",
       "9131   Default  790.000000      image  790.000000  27.0000  27.0000\n",
       "13857  Default  735.000000     people  735.000000  26.0000  26.0000\n",
       "18743  Default  699.000000      think  699.000000  25.0000  25.0000\n",
       "14763  Default  497.000000    program  497.000000  24.0000  24.0000\n",
       "7056   Default  508.000000       file  508.000000  23.0000  23.0000\n",
       "3432   Default  325.000000  christian  325.000000  22.0000  22.0000\n",
       "4785   Default  416.000000       data  416.000000  21.0000  21.0000\n",
       "12512  Default  387.000000       nasa  387.000000  20.0000  20.0000\n",
       "10671  Default  372.000000     launch  372.000000  19.0000  19.0000\n",
       "20719  Default  239.000000       word  239.000000  18.0000  18.0000\n",
       "2219   Default  385.000000    believe  385.000000  17.0000  17.0000\n",
       "11580  Default   89.000000    matthew   89.000000  16.0000  16.0000\n",
       "16421  Default  266.000000  satellite  266.000000  15.0000  15.0000\n",
       "2333   Default  257.000000      bible  257.000000  14.0000  14.0000\n",
       "15648  Default  278.000000   religion  278.000000  13.0000  13.0000\n",
       "4818   Default  234.000000        day  234.000000  12.0000  12.0000\n",
       "7321   Default  261.000000     format  261.000000  11.0000  11.0000\n",
       "17311  Default  277.000000   software  277.000000  10.0000  10.0000\n",
       "1748   Default  235.000000    atheist  235.000000   9.0000   9.0000\n",
       "1542   Default  228.000000   argument  228.000000   8.0000   8.0000\n",
       "10143  Default  243.000000       jpeg  243.000000   7.0000   7.0000\n",
       "8069   Default  274.000000    graphic  274.000000   6.0000   6.0000\n",
       "7494   Default  239.000000        ftp  239.000000   5.0000   5.0000\n",
       "1892   Default  294.000000  available  294.000000   4.0000   4.0000\n",
       "13316  Default  236.000000      orbit  236.000000   3.0000   3.0000\n",
       "15158  Default   68.000000         ra   68.000000   2.0000   2.0000\n",
       "5959   Default  403.000000        edu  403.000000   1.0000   1.0000\n",
       "...        ...         ...        ...         ...      ...      ...\n",
       "13534   Topic3   11.729114        p23   12.349231   2.3946  -7.2906\n",
       "2945    Topic3   12.416426  caligiuri   13.075405   2.3944  -7.2336\n",
       "15158   Topic3   63.609885         ra   68.992217   2.3649  -5.5999\n",
       "8117    Topic3   44.787006      greek   48.290564   2.3708  -5.9507\n",
       "10046   Topic3  214.327445      jesus  315.799908   2.0585  -4.3852\n",
       "11098   Topic3   39.248123       lord   47.556481   2.2541  -6.0828\n",
       "8344    Topic3   29.835062       hang   36.493700   2.2446  -6.3570\n",
       "11735   Topic3   49.881663        men   67.216828   2.1478  -5.8430\n",
       "14831   Topic3   33.555248   prophecy   45.647887   2.1383  -6.2395\n",
       "16519   Topic3   22.758137    scholar   28.828547   2.2096  -6.6277\n",
       "13715   Topic3   40.807750    passage   63.648497   2.0016  -6.0438\n",
       "19912   Topic3   24.227924        van   33.087354   2.1344  -6.5652\n",
       "3426    Topic3   43.024410     christ   79.550725   1.8315  -5.9909\n",
       "8746    Topic3   25.706659       holy   36.259523   2.1021  -6.5059\n",
       "7661    Topic3   28.354279         gd   43.496130   2.0182  -6.4079\n",
       "20054   Topic3   31.365025      verse   59.112288   1.8123  -6.3070\n",
       "10097   Topic3   43.771190       john  115.027046   1.4799  -5.9737\n",
       "20719   Topic3   62.431594       word  239.642821   1.1010  -5.6186\n",
       "17468   Topic3   35.790706      speak   84.837655   1.5830  -6.1750\n",
       "4808    Topic3   36.444203      david   92.390956   1.5158  -6.1569\n",
       "10402   Topic3   27.271642       king   45.954726   1.9243  -6.4468\n",
       "7939    Topic3   74.809191        god  707.449828   0.1994  -5.4377\n",
       "4818    Topic3   49.450773        day  234.046762   0.8915  -5.8517\n",
       "3432    Topic3   52.457795  christian  325.680157   0.6202  -5.7926\n",
       "17075   Topic3   29.269167        sin   56.616911   1.7863  -6.3761\n",
       "11376   Topic3   38.449822        man  151.415064   1.0754  -6.1033\n",
       "4843    Topic3   30.701690         de   72.912905   1.5811  -6.3283\n",
       "3778    Topic3   30.623821        com  154.527313   0.8275  -6.3309\n",
       "11132   Topic3   29.633199       love  117.102247   1.0719  -6.3638\n",
       "12493   Topic3   29.141228       name  208.782199   0.4769  -6.3805\n",
       "\n",
       "[220 rows x 6 columns], token_table=       Topic      Freq         Term\n",
       "term                               \n",
       "252        1  0.993378           3d\n",
       "911        2  0.987712        agree\n",
       "911        3  0.014110        agree\n",
       "1340       1  0.036377     anything\n",
       "1340       2  0.963989     anything\n",
       "1504       3  0.988666       archer\n",
       "1538       2  0.998508        argue\n",
       "1542       2  0.995357     argument\n",
       "1747       2  0.996196      atheism\n",
       "1748       2  0.997899      atheist\n",
       "1892       1  0.965597    available\n",
       "1892       2  0.034000    available\n",
       "2216       2  0.995598       belief\n",
       "2219       1  0.033749      believe\n",
       "2219       2  0.965728      believe\n",
       "2219       3  0.002596      believe\n",
       "2333       2  0.900210        bible\n",
       "2333       3  0.097005        bible\n",
       "2521       3  0.918179        bobbe\n",
       "2945       3  0.917754    caligiuri\n",
       "3203       1  0.944242       center\n",
       "3203       2  0.050226       center\n",
       "3203       3  0.005023       center\n",
       "3426       2  0.452541       christ\n",
       "3426       3  0.540536       christ\n",
       "3432       2  0.838246    christian\n",
       "3432       3  0.159666    christian\n",
       "3515       1  0.033360        claim\n",
       "3515       2  0.957908        claim\n",
       "3515       3  0.009531        claim\n",
       "...      ...       ...          ...\n",
       "19779      1  0.633161          use\n",
       "19779      2  0.366722          use\n",
       "19787      1  0.979199         user\n",
       "19787      2  0.018711         user\n",
       "19912      1  0.272007          van\n",
       "19912      3  0.725353          van\n",
       "19990      1  0.994783      vehicle\n",
       "20054      2  0.456758        verse\n",
       "20054      3  0.524426        verse\n",
       "20361      2  0.992260          war\n",
       "20414      1  0.173471          way\n",
       "20414      2  0.807878          way\n",
       "20414      3  0.019825          way\n",
       "20476      1  0.247955         well\n",
       "20476      2  0.752132         well\n",
       "20719      1  0.162742         word\n",
       "20719      2  0.575857         word\n",
       "20719      3  0.258718         word\n",
       "20727      1  0.619490         work\n",
       "20727      2  0.363950         work\n",
       "20727      3  0.015487         work\n",
       "20792      1  0.027403        wrong\n",
       "20792      2  0.965953        wrong\n",
       "20950      3  0.989626           ye\n",
       "20954      1  0.493489         year\n",
       "20954      2  0.500818         year\n",
       "20954      3  0.007329         year\n",
       "20965      1  0.015207          yes\n",
       "20965      2  0.980858          yes\n",
       "21068      3  0.954975  zoroastrian\n",
       "\n",
       "[335 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "visualization_panel = pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')\n",
    "visualization_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOG-LIKELIHOOD, PERPLEXITY AND COHERENCE SCORES**\n",
    "\n",
    "Log-likelihood, perplexity and coherence scores do not have baseline or a threshold values. \n",
    "They are used to compare and discriminate between models estimated on the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a function CoherenceModel() from the gensim module for computing coherence scores for our LDA topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function CoherenceModel() needs:\n",
    "    * an array of topics in the form [[\"cat\",\"dog\",\"python\"],[\"java\",\"python\",\"ruby\"]], \n",
    "    * corpus with each document represented as bag-of-words, and\n",
    "    * dictionary of the corpus\n",
    "    \n",
    "We will create those elements now using a tokenized corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
    "news_dictionary = Dictionary(news_corpus_tokenized)\n",
    "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the lines of Python code that would estimate an LDA topic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>word_11</th>\n",
       "      <th>word_12</th>\n",
       "      <th>word_13</th>\n",
       "      <th>word_14</th>\n",
       "      <th>word_15</th>\n",
       "      <th>word_16</th>\n",
       "      <th>word_17</th>\n",
       "      <th>word_18</th>\n",
       "      <th>word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>space</td>\n",
       "      <td>image</td>\n",
       "      <td>use</td>\n",
       "      <td>file</td>\n",
       "      <td>program</td>\n",
       "      <td>data</td>\n",
       "      <td>system</td>\n",
       "      <td>launch</td>\n",
       "      <td>nasa</td>\n",
       "      <td>edu</td>\n",
       "      <td>available</td>\n",
       "      <td>software</td>\n",
       "      <td>satellite</td>\n",
       "      <td>graphic</td>\n",
       "      <td>format</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>include</td>\n",
       "      <td>ftp</td>\n",
       "      <td>orbit</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>think</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>god</td>\n",
       "      <td>could</td>\n",
       "      <td>use</td>\n",
       "      <td>well</td>\n",
       "      <td>good</td>\n",
       "      <td>thing</td>\n",
       "      <td>time</td>\n",
       "      <td>take</td>\n",
       "      <td>believe</td>\n",
       "      <td>even</td>\n",
       "      <td>point</td>\n",
       "      <td>way</td>\n",
       "      <td>many</td>\n",
       "      <td>give</td>\n",
       "      <td>much</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>p2</td>\n",
       "      <td>den</td>\n",
       "      <td>p3</td>\n",
       "      <td>p1</td>\n",
       "      <td>com</td>\n",
       "      <td>de</td>\n",
       "      <td>men</td>\n",
       "      <td>van</td>\n",
       "      <td>radius</td>\n",
       "      <td>navy</td>\n",
       "      <td>presentation</td>\n",
       "      <td>bob</td>\n",
       "      <td>edu</td>\n",
       "      <td>het</td>\n",
       "      <td>double</td>\n",
       "      <td>vice</td>\n",
       "      <td>dr</td>\n",
       "      <td>material</td>\n",
       "      <td>een</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_3</th>\n",
       "      <td>jesus</td>\n",
       "      <td>god</td>\n",
       "      <td>christian</td>\n",
       "      <td>bible</td>\n",
       "      <td>know</td>\n",
       "      <td>people</td>\n",
       "      <td>word</td>\n",
       "      <td>matthew</td>\n",
       "      <td>day</td>\n",
       "      <td>law</td>\n",
       "      <td>even</td>\n",
       "      <td>child</td>\n",
       "      <td>point</td>\n",
       "      <td>good</td>\n",
       "      <td>man</td>\n",
       "      <td>christ</td>\n",
       "      <td>time</td>\n",
       "      <td>ra</td>\n",
       "      <td>think</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_0  word_1     word_2 word_3   word_4  word_5  word_6   word_7  \\\n",
       "Topic_0  space   image        use   file  program    data  system   launch   \n",
       "Topic_1  think  people       like   know      god   could     use     well   \n",
       "Topic_2     p2     den         p3     p1      com      de     men      van   \n",
       "Topic_3  jesus     god  christian  bible     know  people    word  matthew   \n",
       "\n",
       "         word_8 word_9       word_10   word_11    word_12  word_13 word_14  \\\n",
       "Topic_0    nasa    edu     available  software  satellite  graphic  format   \n",
       "Topic_1    good  thing          time      take    believe     even   point   \n",
       "Topic_2  radius   navy  presentation       bob        edu      het  double   \n",
       "Topic_3     day    law          even     child      point     good     man   \n",
       "\n",
       "        word_15  word_16   word_17 word_18      word_19  \n",
       "Topic_0    jpeg  include       ftp   orbit  information  \n",
       "Topic_1     way     many      give    much         post  \n",
       "Topic_2    vice       dr  material     een         stay  \n",
       "Topic_3  christ     time        ra   think         many  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_topics_news = 4\n",
    "no_keywords_news = 20\n",
    "lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_news_corpus) \n",
    "topic_keywords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=no_keywords_news)\n",
    "pd.DataFrame(topic_keywords, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_keywords_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_keywords))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the coherence score for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score for the model:  -3.9419\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(topics=topic_keywords, \n",
    "                    corpus = news_corpus_bow , \n",
    "                    dictionary = news_dictionary, coherence='u_mass')\n",
    "print(\"Coherence score for the model: \", np.round(cm.get_coherence(),4))  # get coherence value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see a coherence score by topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score by topic:  [ -1.8577  -1.2833 -11.1032  -1.5232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coherence score by topic: \", np.round(cm.get_coherence_per_topic(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 1**\n",
    "\n",
    "Compare the coherence-scores-based evaluation for models with 2, 3, and 4 topics with your human-judgment-based evaluation of those models. What do you find? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence score for the model is -1.4506, -3.7562, -3.9419 with 2, 3, 4 topics, which doesn't agree with human-judgement-based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood (higher values are better):  -1661737.6873378977\n"
     ]
    }
   ],
   "source": [
    "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (lower values are better):  4315.084570393613\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 2**\n",
    "\n",
    "Compare the perplexity and log-likelihood evaluation for models with 2, 3, and 4 topics with your human-judgment-based evaluation of those models. What do you find? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log likelihood is -166.47k, -166.17k, -166.09k with 2, 3, and 4 topics, and perplexity is 4379, 4315, 4298 with 2, 3, and 4 topics, which agree with human-judgement-based evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 3**\n",
    "\n",
    "Write a simple script that selects the best model automatically. \n",
    "You select a criteria for \"best model\" (log-likelihood, perplexity, or coherence score). \n",
    "You can vary both parameter alpha and number of topics, or just number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>word_11</th>\n",
       "      <th>word_12</th>\n",
       "      <th>word_13</th>\n",
       "      <th>word_14</th>\n",
       "      <th>word_15</th>\n",
       "      <th>word_16</th>\n",
       "      <th>word_17</th>\n",
       "      <th>word_18</th>\n",
       "      <th>word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>space</td>\n",
       "      <td>image</td>\n",
       "      <td>use</td>\n",
       "      <td>file</td>\n",
       "      <td>program</td>\n",
       "      <td>data</td>\n",
       "      <td>system</td>\n",
       "      <td>launch</td>\n",
       "      <td>nasa</td>\n",
       "      <td>edu</td>\n",
       "      <td>available</td>\n",
       "      <td>software</td>\n",
       "      <td>satellite</td>\n",
       "      <td>graphic</td>\n",
       "      <td>format</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>include</td>\n",
       "      <td>ftp</td>\n",
       "      <td>orbit</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>think</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>god</td>\n",
       "      <td>could</td>\n",
       "      <td>use</td>\n",
       "      <td>well</td>\n",
       "      <td>good</td>\n",
       "      <td>thing</td>\n",
       "      <td>time</td>\n",
       "      <td>take</td>\n",
       "      <td>believe</td>\n",
       "      <td>even</td>\n",
       "      <td>point</td>\n",
       "      <td>way</td>\n",
       "      <td>many</td>\n",
       "      <td>give</td>\n",
       "      <td>much</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>p2</td>\n",
       "      <td>den</td>\n",
       "      <td>p3</td>\n",
       "      <td>p1</td>\n",
       "      <td>com</td>\n",
       "      <td>de</td>\n",
       "      <td>men</td>\n",
       "      <td>van</td>\n",
       "      <td>radius</td>\n",
       "      <td>navy</td>\n",
       "      <td>presentation</td>\n",
       "      <td>bob</td>\n",
       "      <td>edu</td>\n",
       "      <td>het</td>\n",
       "      <td>double</td>\n",
       "      <td>vice</td>\n",
       "      <td>dr</td>\n",
       "      <td>material</td>\n",
       "      <td>een</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_3</th>\n",
       "      <td>jesus</td>\n",
       "      <td>god</td>\n",
       "      <td>christian</td>\n",
       "      <td>bible</td>\n",
       "      <td>know</td>\n",
       "      <td>people</td>\n",
       "      <td>word</td>\n",
       "      <td>matthew</td>\n",
       "      <td>day</td>\n",
       "      <td>law</td>\n",
       "      <td>even</td>\n",
       "      <td>child</td>\n",
       "      <td>point</td>\n",
       "      <td>good</td>\n",
       "      <td>man</td>\n",
       "      <td>christ</td>\n",
       "      <td>time</td>\n",
       "      <td>ra</td>\n",
       "      <td>think</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_0  word_1     word_2 word_3   word_4  word_5  word_6   word_7  \\\n",
       "Topic_0  space   image        use   file  program    data  system   launch   \n",
       "Topic_1  think  people       like   know      god   could     use     well   \n",
       "Topic_2     p2     den         p3     p1      com      de     men      van   \n",
       "Topic_3  jesus     god  christian  bible     know  people    word  matthew   \n",
       "\n",
       "         word_8 word_9       word_10   word_11    word_12  word_13 word_14  \\\n",
       "Topic_0    nasa    edu     available  software  satellite  graphic  format   \n",
       "Topic_1    good  thing          time      take    believe     even   point   \n",
       "Topic_2  radius   navy  presentation       bob        edu      het  double   \n",
       "Topic_3     day    law          even     child      point     good     man   \n",
       "\n",
       "        word_15  word_16   word_17 word_18      word_19  \n",
       "Topic_0    jpeg  include       ftp   orbit  information  \n",
       "Topic_1     way     many      give    much         post  \n",
       "Topic_2    vice       dr  material     een         stay  \n",
       "Topic_3  christ     time        ra   think         many  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = 1000000\n",
    "for no_topics_news in range(2,5):\n",
    "    lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_news_corpus)\n",
    "    perplexity = min(perplexity, lda_news.perplexity(bow_news_corpus))\n",
    "    if perplexity==lda_news.perplexity(bow_news_corpus):\n",
    "        best = lda_news\n",
    "topic_keywords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = best, n_words=no_keywords_news)\n",
    "pd.DataFrame(topic_keywords, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_keywords_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_keywords))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=100,\n",
       "             mean_change_tol=0.001, n_components=4, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=42,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
