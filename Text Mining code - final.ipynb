{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining\n",
    "### Install necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html.parser\n",
      "Requirement already satisfied: ply in /anaconda3/lib/python3.6/site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "Requirement already satisfied: pattern3 in /anaconda3/lib/python3.6/site-packages (3.0.0)\n",
      "Requirement already satisfied: cherrypy in /anaconda3/lib/python3.6/site-packages (from pattern3) (18.1.1)\n",
      "Requirement already satisfied: feedparser in /anaconda3/lib/python3.6/site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: docx in /anaconda3/lib/python3.6/site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: simplejson in /anaconda3/lib/python3.6/site-packages (from pattern3) (3.16.0)\n",
      "Requirement already satisfied: pdfminer3k in /anaconda3/lib/python3.6/site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: pdfminer.six in /anaconda3/lib/python3.6/site-packages (from pattern3) (20181108)\n",
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.6/site-packages (from pattern3) (4.6.0)\n",
      "Requirement already satisfied: cheroot>=6.2.4 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (6.5.4)\n",
      "Requirement already satisfied: portend>=2.1.1 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (2.3)\n",
      "Requirement already satisfied: more-itertools in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (4.1.0)\n",
      "Requirement already satisfied: zc.lockfile in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (1.4)\n",
      "Requirement already satisfied: lxml in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (4.2.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (5.1.0)\n",
      "Requirement already satisfied: pytest>=2.0 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.5.1)\n",
      "Requirement already satisfied: ply>=3.4 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: pycryptodome in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (3.8.1)\n",
      "Requirement already satisfied: sortedcontainers in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.5.10)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.11.0)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /anaconda3/lib/python3.6/site-packages (from cheroot>=6.2.4->cherrypy->pattern3) (1.5)\n",
      "Requirement already satisfied: tempora>=1.8 in /anaconda3/lib/python3.6/site-packages (from portend>=2.1.1->cherrypy->pattern3) (1.14)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from zc.lockfile->cherrypy->pattern3) (39.1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (18.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: jaraco.functools>=1.20 in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2018.4)\n",
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob, os  \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "%run ./Text_Normalization_Function.ipynb\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Process Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"database_final.csv\")\n",
    "comments = []\n",
    "for i in data.loc[:,\"comments\"]:\n",
    "    comments.append(str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate non-English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords   # stopwords to detect language\n",
    "from nltk import wordpunct_tokenize # function to split up our words\n",
    "\n",
    "def get_language_likelihood(input_text):\n",
    "    \"\"\"Return a dictionary of languages and their likelihood of being the \n",
    "    natural language of the input text\n",
    "    \"\"\"\n",
    " \n",
    "    input_text = input_text.lower()\n",
    "    input_words = wordpunct_tokenize(input_text)\n",
    " \n",
    "    language_likelihood = {}\n",
    "    total_matches = 0\n",
    "    for language in stopwords._fileids:\n",
    "        language_likelihood[language] = len(set(input_words) &\n",
    "                set(stopwords.words(language)))\n",
    " \n",
    "    return language_likelihood\n",
    " \n",
    "def get_language(input_text):\n",
    "    \"\"\"Return the most likely language of the given text\n",
    "    \"\"\" \n",
    "    likelihoods = get_language_likelihood(input_text)\n",
    "    return sorted(likelihoods, key=likelihoods.get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_f = [r for r in comments if pd.notnull(r) and get_language(r) == 'english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_test_corpus = normalize_corpus(reviews_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling for All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_words(vectorizer, lda_model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer_news = CountVectorizer()\n",
    "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_test_corpus)\n",
    "bow_feature_names_news = bow_vectorizer_news.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics_news = 6\n",
    "lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_news_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>stay</td>\n",
       "      <td>great</td>\n",
       "      <td>place</td>\n",
       "      <td>location</td>\n",
       "      <td>host</td>\n",
       "      <td>clean</td>\n",
       "      <td>recommend</td>\n",
       "      <td>nice</td>\n",
       "      <td>lovely</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>market</td>\n",
       "      <td>keep</td>\n",
       "      <td>cook</td>\n",
       "      <td>basic</td>\n",
       "      <td>without</td>\n",
       "      <td>bad</td>\n",
       "      <td>plus</td>\n",
       "      <td>seem</td>\n",
       "      <td>smell</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>host</td>\n",
       "      <td>day</td>\n",
       "      <td>arrival</td>\n",
       "      <td>cancel</td>\n",
       "      <td>reservation</td>\n",
       "      <td>posting</td>\n",
       "      <td>automated</td>\n",
       "      <td>answer</td>\n",
       "      <td>happy</td>\n",
       "      <td>communicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_3</th>\n",
       "      <td>walk</td>\n",
       "      <td>station</td>\n",
       "      <td>close</td>\n",
       "      <td>london</td>\n",
       "      <td>great</td>\n",
       "      <td>tube</td>\n",
       "      <td>minute</td>\n",
       "      <td>place</td>\n",
       "      <td>location</td>\n",
       "      <td>apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_4</th>\n",
       "      <td>us</td>\n",
       "      <td>even</td>\n",
       "      <td>check</td>\n",
       "      <td>time</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>like</td>\n",
       "      <td>could</td>\n",
       "      <td>stay</td>\n",
       "      <td>give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_5</th>\n",
       "      <td>room</td>\n",
       "      <td>good</td>\n",
       "      <td>bed</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>night</td>\n",
       "      <td>shower</td>\n",
       "      <td>bit</td>\n",
       "      <td>small</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_0   word_1   word_2    word_3       word_4   word_5     word_6  \\\n",
       "Topic_0    stay    great    place  location         host    clean  recommend   \n",
       "Topic_1  market     keep     cook     basic      without      bad       plus   \n",
       "Topic_2    host      day  arrival    cancel  reservation  posting  automated   \n",
       "Topic_3    walk  station    close    london        great     tube     minute   \n",
       "Topic_4      us     even    check      time         home    house       like   \n",
       "Topic_5    room     good      bed  bathroom      kitchen    night     shower   \n",
       "\n",
       "         word_7    word_8       word_9  \n",
       "Topic_0    nice    lovely       london  \n",
       "Topic_1    seem     smell         high  \n",
       "Topic_2  answer     happy  communicate  \n",
       "Topic_3   place  location    apartment  \n",
       "Topic_4   could      stay         give  \n",
       "Topic_5     bit     small         flat  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words_news = 10\n",
    "topic_words = get_topic_words(vectorizer = bow_vectorizer_news, \n",
    "                              lda_model = lda_news, \n",
    "                              n_words = no_top_words_news)\n",
    "pd.DataFrame(topic_words, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_top_words_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>0.051261</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.006841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.008081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.030915</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host</th>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.073315</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>0.028407</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.010185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend</th>\n",
       "      <td>0.024718</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>london</th>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5\n",
       "stay       0.051261  0.000005  0.000005  0.009805  0.009519  0.006841\n",
       "great      0.047854  0.000005  0.000005  0.021074  0.000002  0.000001\n",
       "place      0.041447  0.000005  0.000005  0.018962  0.000412  0.008081\n",
       "location   0.030915  0.000005  0.000005  0.018916  0.000002  0.006723\n",
       "host       0.029994  0.000005  0.073315  0.000001  0.003792  0.000104\n",
       "clean      0.028407  0.000005  0.000005  0.010811  0.000002  0.010185\n",
       "recommend  0.024718  0.000005  0.000005  0.002476  0.000002  0.000001\n",
       "nice       0.019726  0.000005  0.000005  0.012013  0.000020  0.006186\n",
       "lovely     0.017839  0.000005  0.000005  0.001917  0.000002  0.000001\n",
       "london     0.016915  0.000005  0.000005  0.023658  0.000917  0.000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
    "word_weights_df = pd.DataFrame(word_weights.T, \n",
    "                               index = bow_feature_names_news, \n",
    "                               columns = [\"Topic_\" + str(i) for i in range(no_topics_news)])\n",
    "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_news_output = lda_news.transform(bow_news_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc_0</th>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_1</th>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_2</th>\n",
       "      <td>0.5131</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_3</th>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.4151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_4</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_5</th>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_6</th>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_7</th>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_8</th>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  Topic_5  dominant_topic\n",
       "Doc_0   0.8217   0.0152   0.0152   0.0152   0.1176   0.0152               0\n",
       "Doc_1   0.4184   0.0035   0.0035   0.0558   0.2043   0.3145               0\n",
       "Doc_2   0.5131   0.0238   0.0238   0.0239   0.0238   0.3916               0\n",
       "Doc_3   0.3918   0.0079   0.0080   0.0726   0.1045   0.4151               5\n",
       "Doc_4   0.0009   0.0009   0.0009   0.2691   0.6481   0.0800               4\n",
       "Doc_5   0.0836   0.2224   0.0073   0.5058   0.0072   0.1737               3\n",
       "Doc_6   0.3138   0.0048   0.0048   0.0048   0.1918   0.4800               5\n",
       "Doc_7   0.0054   0.0054   0.0054   0.6648   0.2325   0.0865               3\n",
       "Doc_8   0.9304   0.0139   0.0139   0.0139   0.0139   0.0139               0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names = [\"Doc_\" + str(i) for i in range(len(reviews_f))]\n",
    "topic_names = [\"Topic_\" + str(i) for i in range(no_topics_news)]\n",
    "df_document_topic = pd.DataFrame(np.round(lda_news_output, 4), columns=topic_names, index=doc_names)\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "df_document_topic[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el353951121541274804187150278\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el353951121541274804187150278_data = {\"mdsDat\": {\"x\": [18.66920280456543, 56.526554107666016, -90.81999206542969, 109.73445129394531, -67.42264556884766, 5.33754825592041], \"y\": [90.3270492553711, -108.24772644042969, 30.150516510009766, 4.792168140411377, -92.57525634765625, -15.11054515838623], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [39.08611446333246, 21.757650542237396, 15.440457556991724, 14.344205446745736, 5.03860838657347, 4.332963604119221]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"Freq\": [11261.0, 16964.0, 3118.0, 5020.0, 4735.0, 4098.0, 7945.0, 4702.0, 7430.0, 1595.0, 3083.0, 3035.0, 8661.0, 15756.0, 3546.0, 17911.0, 12555.0, 5383.0, 1132.0, 1099.0, 2424.0, 1052.0, 8377.0, 1048.0, 2165.0, 2043.0, 10946.0, 3462.0, 4624.0, 1815.0, 2852.555704729686, 2698.5791267562613, 2869.958309316055, 1882.712337628226, 1229.2291629819226, 729.9606676543075, 565.1460285660412, 519.9248234723697, 497.70419826897995, 494.11143584541577, 430.4896913486041, 337.67963891300434, 332.0511361033884, 319.7715166887247, 311.51152120714215, 298.46176764740636, 281.52388164827835, 259.5190992888268, 239.82741854446152, 236.26476121334608, 228.978138624364, 222.3473117256342, 206.10774151343065, 204.91751011494497, 197.4244382031993, 185.1142176028253, 723.1503597883632, 172.56305790437972, 158.91289444890313, 157.41297421329455, 973.4428334365689, 7036.949310261285, 5078.740678772609, 777.7052769031421, 1823.7676675978423, 3429.911422526845, 1264.0929720366041, 1721.5580360464746, 2239.516998567223, 14593.54818524901, 13623.603158616705, 2178.3191567458903, 1356.5119828931283, 11799.70573087226, 4182.987900829951, 8538.993686503141, 1956.0195976191178, 8087.1874212660205, 3677.0590543465783, 8801.432744952266, 4074.042066009326, 4563.088151064679, 5615.900681758112, 1710.4704869493717, 1530.3524399004034, 4815.485509470927, 4165.642347274133, 4233.85456451002, 3016.2860265652976, 3759.4116528439945, 3242.347268218276, 2185.704923381702, 2476.6418289730036, 2437.2870196094973, 2030.3993257043824, 2016.6888311558066, 5019.619652402597, 4734.566361081989, 3082.2969477987403, 3034.4225462363606, 2164.5108374024358, 2043.0288012555777, 1669.8091834449322, 1664.5919268886255, 1621.4290303920088, 1475.007658141142, 1351.4249164531348, 1183.9610001172032, 1105.923453855878, 1101.5326214337201, 1038.1463591558067, 993.988852140384, 857.0369064478465, 761.1783776248202, 682.8695508455883, 691.3088882110507, 666.8206891109727, 640.9649427659514, 623.8160966360091, 596.9570228085424, 547.4862317003226, 541.3173586425307, 479.6334892657403, 452.9366001263467, 418.5006502319793, 344.2341122505409, 4345.961499550934, 1546.5137221152656, 1410.2424406375071, 1328.3205164626195, 957.8186148055452, 3749.2914045533084, 2146.8760132140633, 1398.617950238059, 1173.212199722475, 2206.945124313035, 2997.741041155365, 2285.541290473311, 3339.7220136671694, 3005.019906704826, 1413.558744501852, 1997.5927579071345, 1903.7381913630477, 1585.6356548699225, 1364.1469286261668, 1713.2285794454358, 1553.8671272496565, 1400.4534210889178, 1339.792240608542, 893.7737971249622, 882.1318079599727, 792.8526840487044, 732.5431027908189, 692.310517948904, 659.5953514139661, 631.5237818851667, 545.0567374673728, 539.8731667825554, 504.3389215548814, 460.8522046339514, 431.9993918050426, 389.24757193492206, 355.9435420040895, 341.67296050437955, 344.2365663612376, 336.13316247211304, 318.491880599991, 312.7122072555154, 299.65374010970953, 292.3796207283792, 285.7520897018869, 280.2003612223518, 277.64900830547475, 271.26279846833285, 270.50845318540735, 254.15087999895232, 249.28708210604998, 419.9540533963713, 550.997337654898, 1254.8288772188482, 1830.5657971610287, 887.538374512811, 826.6131188316577, 543.1486458107036, 1706.9112818160695, 1008.2084932250825, 1518.333746332486, 3539.7694361811623, 1928.6859511984794, 964.9291832698161, 972.4932320877339, 857.9299679945743, 722.9767600577347, 2145.424299497831, 727.3473671037261, 653.0288279069333, 687.8291198000608, 1217.0988251282622, 1193.5992065204175, 1145.4368430838426, 625.752425535141, 647.1491131906184, 689.5010533972046, 908.810539171547, 756.1084060801431, 769.4026848846902, 695.7477444005827, 943.7239507948512, 771.0183691786533, 577.7874545626462, 566.2695148474259, 525.1584369577679, 501.31084146623203, 492.3539342977375, 415.1904793580636, 411.974697752693, 390.2974299655729, 321.2381726692987, 312.9323121676892, 313.7927306074633, 307.49595147320224, 300.69351757222006, 295.3919206246199, 288.5853393371726, 279.29588087170725, 270.74108288880075, 268.5275952798727, 240.89804489414215, 231.4610268476095, 229.98253268533043, 230.10019461709686, 221.0326327954681, 219.42535558796078, 209.5500794236575, 203.00756931984643, 202.95059983904338, 202.6562706838343, 3565.1549880051457, 884.5477488481109, 1514.516421478664, 472.54641123721956, 663.4278835926443, 674.596956294233, 966.530849389268, 901.4883553350182, 424.99033242840613, 405.26023504748935, 492.1935791817379, 515.8109551140674, 431.28315196615864, 590.4739904771901, 745.6292599534892, 1008.7534133995127, 1483.9330131176282, 1114.9348430138339, 608.5451033856473, 1359.242624949005, 1275.7716109120126, 718.1919429309244, 780.6814347998719, 1204.7836885875695, 595.1727720491875, 635.5827806629521, 740.7177292978137, 637.8558860541747, 811.0084047471651, 994.576680591448, 783.4702958058612, 558.6343948247348, 645.2959585232363, 517.5235642515789, 482.79753534782765, 452.08732781654527, 445.49772383862387, 439.7822794096115, 369.2790459523389, 304.6175002051784, 273.4285674906099, 242.2908198280904, 223.24023043214063, 214.08420241644157, 213.0848612776085, 203.64876760412108, 172.68331591830227, 171.8815113825397, 170.94418199346438, 168.58172184296885, 168.30589921763203, 164.02680882761808, 162.0498163301844, 159.4200029160649, 155.8355176934148, 153.6485141613399, 149.2818246817948, 137.50035606451573, 131.01702762611765, 125.98934113666081, 122.0492579709779, 120.50287262465456, 254.49969778634937, 168.3202086005134, 128.98722530926187, 1594.5298400216993, 1131.358745476492, 1099.057344328609, 1051.247964281164, 1047.2658232484525, 583.3724782422249, 579.9992932980058, 502.2445631298456, 394.7481907080349, 366.8535340576759, 357.30423100079116, 355.0005977135694, 352.3239095816904, 330.81196459824497, 303.61360698265696, 273.519551582023, 270.73366177452476, 255.33267870913033, 253.71797132551953, 215.84513939261106, 192.63395286506898, 188.89813355974212, 186.4570519691017, 181.21494466440288, 177.48383968738221, 174.00587110282325, 170.8398075033117, 158.1659993758724, 154.98797997392506, 132.15275153937094, 1994.0044365094623, 2313.824660126896, 158.53104506353657], \"Term\": [\"host\", \"great\", \"day\", \"walk\", \"station\", \"us\", \"room\", \"close\", \"recommend\", \"arrival\", \"tube\", \"minute\", \"london\", \"place\", \"bed\", \"stay\", \"location\", \"lovely\", \"cancel\", \"reservation\", \"bathroom\", \"posting\", \"good\", \"automated\", \"bus\", \"restaurant\", \"clean\", \"home\", \"easy\", \"even\", \"highly\", \"friendly\", \"helpful\", \"amazing\", \"stylish\", \"welcoming\", \"ideal\", \"tip\", \"neighbourhood\", \"facility\", \"brilliant\", \"option\", \"hospitable\", \"soon\", \"parking\", \"spotless\", \"sparkle\", \"dog\", \"david\", \"beautifully\", \"outstanding\", \"spotlessly\", \"chat\", \"john\", \"calm\", \"hesitate\", \"hospitality\", \"appartement\", \"alex\", \"load\", \"view\", \"recommend\", \"lovely\", \"accommodate\", \"beautiful\", \"definitely\", \"best\", \"thanks\", \"super\", \"stay\", \"great\", \"communication\", \"fantastic\", \"place\", \"comfortable\", \"host\", \"thank\", \"clean\", \"perfect\", \"location\", \"everything\", \"really\", \"nice\", \"excellent\", \"wonderful\", \"london\", \"room\", \"good\", \"need\", \"apartment\", \"flat\", \"home\", \"easy\", \"well\", \"house\", \"time\", \"walk\", \"station\", \"tube\", \"minute\", \"bus\", \"restaurant\", \"near\", \"value\", \"shop\", \"underground\", \"min\", \"park\", \"train\", \"stop\", \"distance\", \"nearby\", \"within\", \"far\", \"line\", \"friend\", \"pub\", \"centre\", \"center\", \"supermarket\", \"bar\", \"cafe\", \"main\", \"instruction\", \"grocery\", \"attraction\", \"close\", \"city\", \"away\", \"street\", \"access\", \"london\", \"easy\", \"locate\", \"around\", \"flat\", \"location\", \"apartment\", \"great\", \"place\", \"area\", \"good\", \"nice\", \"well\", \"quiet\", \"clean\", \"stay\", \"shower\", \"bit\", \"floor\", \"door\", \"water\", \"noise\", \"towel\", \"however\", \"explore\", \"hot\", \"second\", \"toilet\", \"fine\", \"cold\", \"stair\", \"hear\", \"ok\", \"hotel\", \"heating\", \"quality\", \"lock\", \"worth\", \"described\", \"pay\", \"totally\", \"bath\", \"homely\", \"fabulous\", \"call\", \"loud\", \"open\", \"window\", \"small\", \"bathroom\", \"sleep\", \"issue\", \"living\", \"kitchen\", \"bedroom\", \"night\", \"room\", \"bed\", \"use\", \"work\", \"people\", \"thing\", \"good\", \"price\", \"overall\", \"expect\", \"flat\", \"apartment\", \"clean\", \"first\", \"quite\", \"little\", \"place\", \"location\", \"stay\", \"nice\", \"touch\", \"property\", \"tea\", \"think\", \"new\", \"thoughtful\", \"noisy\", \"heart\", \"care\", \"cool\", \"allow\", \"pleasure\", \"situate\", \"fresh\", \"airport\", \"real\", \"air\", \"wall\", \"wasnt\", \"put\", \"fix\", \"heat\", \"else\", \"note\", \"bag\", \"communicative\", \"send\", \"beyond\", \"rent\", \"booking\", \"us\", \"leave\", \"even\", \"early\", \"arrive\", \"coffee\", \"give\", \"help\", \"able\", \"extra\", \"late\", \"morning\", \"wifi\", \"every\", \"provide\", \"could\", \"check\", \"like\", \"breakfast\", \"time\", \"home\", \"take\", \"feel\", \"house\", \"felt\", \"airbnb\", \"day\", \"much\", \"need\", \"stay\", \"really\", \"everything\", \"market\", \"keep\", \"cook\", \"basic\", \"without\", \"bad\", \"plus\", \"seem\", \"smell\", \"review\", \"polite\", \"standard\", \"cleaning\", \"phone\", \"downstairs\", \"sound\", \"later\", \"maybe\", \"sort\", \"soap\", \"uncomfortable\", \"accurate\", \"half\", \"equipment\", \"shampoo\", \"fact\", \"hang\", \"maintain\", \"general\", \"de\", \"high\", \"full\", \"despite\", \"arrival\", \"cancel\", \"reservation\", \"posting\", \"automated\", \"answer\", \"happy\", \"communicate\", \"link\", \"king\", \"youre\", \"nothing\", \"cross\", \"incredibly\", \"cant\", \"attentive\", \"expectation\", \"literally\", \"recommendation\", \"immediately\", \"thoroughly\", \"hyde\", \"special\", \"oxford\", \"anna\", \"daughter\", \"gem\", \"ground\", \"greet\", \"enjoyed\", \"day\", \"host\", \"gorgeous\"], \"Total\": [11261.0, 16964.0, 3118.0, 5020.0, 4735.0, 4098.0, 7945.0, 4702.0, 7430.0, 1595.0, 3083.0, 3035.0, 8661.0, 15756.0, 3546.0, 17911.0, 12555.0, 5383.0, 1132.0, 1099.0, 2424.0, 1052.0, 8377.0, 1048.0, 2165.0, 2043.0, 10946.0, 3462.0, 4624.0, 1815.0, 2853.3958253942506, 2699.4205065494143, 2870.8629958476563, 1883.554105460388, 1230.0704432936245, 730.8010803968441, 565.9949168809859, 520.7670050801272, 498.5488359942362, 494.95774339208134, 431.3303931450923, 338.5331329625449, 332.89160385248005, 320.6214805548038, 312.3573576905853, 299.3038345634539, 282.36530740142143, 260.36871231379655, 240.66803138231052, 237.10709155629362, 229.81992808707824, 223.1900946569164, 206.95488192543718, 205.75995838915887, 198.26992592946786, 185.95633013352364, 726.7014285731146, 173.4115893308634, 159.75715379521776, 158.26147463032726, 980.9655627033067, 7430.060859378797, 5383.293484754574, 799.7235010548006, 1914.0916209064976, 3700.3553638316857, 1332.475957529063, 1840.6873651686017, 2479.8436654751877, 17911.739543359552, 16964.002298953597, 2505.1334268449014, 1523.074735035669, 15756.929293099287, 5179.900007885166, 11261.014165868422, 2272.8640265557083, 10946.364278246496, 4674.562376914784, 12555.79320069445, 5383.098304125963, 6249.848919285636, 8217.82378811526, 2075.527663033499, 1823.4874988123597, 8661.069210581978, 7945.895244303819, 8377.38286156742, 5215.091815172322, 7424.007036550345, 6746.588720654158, 3462.150760969689, 4624.195495097037, 5005.684694094612, 3911.6825107643253, 3788.437660868061, 5020.455799924179, 4735.401664487365, 3083.1321819046943, 3035.260075805264, 2165.3460605340647, 2043.8641102628876, 1670.6461618325757, 1665.4306433515717, 1622.264453881891, 1475.842667531916, 1352.2614145005516, 1184.799710966198, 1106.7600755437384, 1102.369444696752, 1038.9809782408897, 994.8258492559514, 857.8741665939953, 762.021614771301, 683.7058663660798, 692.1579475358761, 667.6570000803226, 641.8010731416057, 624.6516605000611, 597.7916098821122, 548.3243887718249, 542.1538687682972, 480.47488207737695, 453.78466193436014, 419.3358280980767, 345.0695581239651, 4702.563636833113, 1799.0717832408054, 1767.7784791478812, 1673.7929084527007, 1209.1510594550577, 8661.069210581978, 4624.195495097037, 2345.3708109244626, 1893.8845500446666, 6746.588720654158, 12555.79320069445, 7424.007036550345, 16964.002298953597, 15756.929293099287, 3152.7201851379723, 8377.38286156742, 8217.82378811526, 5005.684694094612, 2991.808112436234, 10946.364278246496, 17911.739543359552, 1401.2875379833768, 1340.62669737116, 894.6090087344417, 882.9673955636085, 793.6865723028646, 733.3765665489013, 693.146415845367, 660.4299090305948, 632.3653853706205, 545.8899447730163, 540.7104851569576, 505.17175297453304, 461.6861647462329, 432.8329774106849, 390.08233219714845, 356.7777763684329, 342.5072654073811, 345.0774479922285, 336.9670227036148, 319.33026410948673, 313.5452957269333, 300.4890424582024, 293.2173607044188, 286.58802265315404, 281.03948607945415, 278.4840260040041, 272.1052197960937, 271.3492790506309, 254.98920279914077, 250.11993412320024, 424.1725566235748, 570.315645348687, 1555.978851475886, 2424.4793261209825, 1077.7646814697057, 1005.3795072827778, 614.0747587328875, 2402.643677910659, 1410.5067123180154, 2500.8204195018393, 7945.895244303819, 3546.0570835574435, 1491.1936600616573, 1592.9329554985247, 1454.8452353958535, 1134.835447239107, 8377.38286156742, 1171.859386584379, 1013.9108341017272, 1147.2822182355508, 6746.588720654158, 7424.007036550345, 10946.364278246496, 981.1546876391552, 1166.0355705494967, 1802.5960179132803, 15756.929293099287, 12555.79320069445, 17911.739543359552, 8217.82378811526, 944.5579930074778, 771.854292621141, 578.6207909580563, 567.105201596948, 525.9941644000091, 502.14510291979065, 493.1935154223133, 416.027304388926, 412.8083348478446, 391.133377039513, 322.0751018163973, 313.76694162633663, 314.63008510403444, 308.33112561175096, 301.52905492745265, 296.2265593401501, 289.41932111006184, 280.1323434652138, 271.5776845375015, 269.36472096231586, 241.73397496185189, 232.2974256942943, 230.81819264486853, 230.93629839543144, 221.8660504899803, 220.26223765484715, 210.38552303561767, 203.84209676086306, 203.78600804497881, 203.491404664318, 4098.239350820344, 981.6065084174295, 1815.7136263223426, 538.3906947728418, 809.0372374329356, 867.6532826207858, 1363.261413856847, 1255.8542165960132, 496.1455594973214, 475.0939553477263, 618.863244646449, 679.7224104339077, 527.1685896496149, 837.5301445812385, 1213.7140289407612, 2088.431518373731, 3898.391926294678, 2520.2758453048264, 945.740486102657, 3788.437660868061, 3462.150760969689, 1337.2802128525034, 1586.2665638855922, 3911.6825107643253, 1223.536545338538, 1638.2901709779776, 3118.875240973972, 1819.754874959646, 5215.091815172322, 17911.739543359552, 6249.848919285636, 5383.098304125963, 646.1252919086348, 518.3522689755271, 483.6265972114205, 452.9150744699939, 446.3253910022483, 440.60818489946183, 370.10821041996576, 305.44589267997213, 274.25455867378514, 243.11679993919796, 224.0679512732133, 214.91063680331206, 213.91090578393346, 204.47748414949584, 173.51229171874368, 172.70947597887903, 171.7726846560195, 169.41000808954726, 169.13474848160558, 164.85409010564632, 162.87758706147264, 160.24834118130713, 156.66349689234747, 154.4752632718736, 150.1094879297925, 138.32793548587554, 131.84548868858226, 126.81657327518101, 122.87593665558711, 121.32458212105355, 586.6864727470336, 470.01520203795303, 217.17556048108077, 1595.356682715773, 1132.1834423683954, 1099.8819235181081, 1052.0721459864124, 1048.0899659960094, 584.2060941675585, 580.8321638659197, 503.0760938200208, 395.5791939836221, 367.6829895394315, 358.13780298158116, 355.8346879349553, 353.1540778747096, 331.64400484755413, 304.4455500658261, 274.3496052739987, 271.56428472200747, 256.1676639267697, 254.5502676824731, 216.67985528311397, 193.4649082874709, 189.73349487976395, 187.2886290837365, 182.04655557730328, 178.31401663673356, 174.83930297313478, 171.67033920996843, 159.00319882931285, 155.82291919682132, 132.98233224367672, 3118.875240973972, 11261.014165868422, 263.94508133086595], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9391, 0.9391, 0.9391, 0.939, 0.9387, 0.9383, 0.9379, 0.9378, 0.9377, 0.9377, 0.9375, 0.9369, 0.9369, 0.9367, 0.9367, 0.9366, 0.9364, 0.9361, 0.9359, 0.9358, 0.9357, 0.9356, 0.9353, 0.9353, 0.9351, 0.9349, 0.9345, 0.9345, 0.9341, 0.934, 0.9317, 0.885, 0.8812, 0.9115, 0.8911, 0.8635, 0.8867, 0.8725, 0.8375, 0.7345, 0.7201, 0.7996, 0.8236, 0.6502, 0.7256, 0.6627, 0.7893, 0.6367, 0.6994, 0.5841, 0.6608, 0.6248, 0.5587, 0.746, 0.7642, 0.3524, 0.2936, 0.257, 0.3919, 0.2589, 0.2067, 0.4795, 0.315, 0.2197, 0.2837, 0.3089, 1.525, 1.525, 1.5249, 1.5249, 1.5248, 1.5248, 1.5247, 1.5247, 1.5247, 1.5246, 1.5246, 1.5245, 1.5244, 1.5244, 1.5244, 1.5244, 1.5242, 1.5241, 1.524, 1.524, 1.524, 1.5239, 1.5239, 1.5238, 1.5237, 1.5237, 1.5235, 1.5233, 1.5232, 1.5228, 1.4463, 1.3739, 1.2992, 1.294, 1.2922, 0.6879, 0.7579, 1.0082, 1.0463, 0.4078, 0.0929, 0.3471, -0.1, -0.1318, 0.723, 0.0916, 0.0627, 0.3756, 0.7399, -0.3294, -0.9195, 1.8676, 1.8676, 1.8672, 1.8672, 1.8671, 1.867, 1.867, 1.8669, 1.8668, 1.8667, 1.8666, 1.8665, 1.8664, 1.8663, 1.866, 1.8658, 1.8657, 1.8657, 1.8657, 1.8656, 1.8655, 1.8654, 1.8653, 1.8653, 1.8652, 1.8652, 1.8651, 1.8651, 1.8649, 1.8648, 1.8582, 1.8337, 1.6531, 1.5872, 1.674, 1.6724, 1.7454, 1.5263, 1.5324, 1.3692, 1.0596, 1.2592, 1.4329, 1.3747, 1.34, 1.4173, 0.506, 1.3912, 1.4282, 1.3566, 0.1556, 0.0404, -0.389, 1.4184, 1.2794, 0.9072, -0.9847, -0.9416, -1.2794, -0.6009, 1.9409, 1.9407, 1.9404, 1.9403, 1.9402, 1.9402, 1.9401, 1.9398, 1.9398, 1.9397, 1.9392, 1.9392, 1.9392, 1.9391, 1.939, 1.939, 1.9389, 1.9388, 1.9387, 1.9387, 1.9384, 1.9382, 1.9382, 1.9382, 1.9381, 1.938, 1.9378, 1.9377, 1.9377, 1.9377, 1.8025, 1.8377, 1.7604, 1.8114, 1.7434, 1.6901, 1.5979, 1.6103, 1.787, 1.7828, 1.7128, 1.6659, 1.7411, 1.5923, 1.4546, 1.2141, 0.976, 1.1263, 1.5009, 0.9168, 0.9435, 1.3202, 1.2329, 0.7642, 1.2212, 0.995, 0.5042, 0.8935, 0.0808, -0.9491, -0.1348, -0.3237, 2.9868, 2.9864, 2.9863, 2.9862, 2.9862, 2.9862, 2.9858, 2.9853, 2.985, 2.9846, 2.9843, 2.9842, 2.9842, 2.984, 2.9833, 2.9832, 2.9832, 2.9831, 2.9831, 2.983, 2.9829, 2.9829, 2.9827, 2.9827, 2.9825, 2.982, 2.9817, 2.9815, 2.9813, 2.9812, 2.1528, 1.9611, 2.467, 3.1384, 3.1382, 3.1382, 3.1381, 3.1381, 3.1375, 3.1375, 3.1373, 3.1368, 3.1367, 3.1366, 3.1366, 3.1366, 3.1364, 3.1362, 3.1359, 3.1359, 3.1357, 3.1356, 3.1351, 3.1346, 3.1345, 3.1345, 3.1343, 3.1343, 3.1341, 3.1341, 3.1336, 3.1335, 3.1327, 2.6916, 1.5565, 2.6291], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.6032, -4.6587, -4.5971, -5.0187, -5.445, -5.9662, -6.2221, -6.3055, -6.3492, -6.3564, -6.4942, -6.7371, -6.7539, -6.7916, -6.8177, -6.8605, -6.919, -7.0003, -7.0792, -7.0942, -7.1255, -7.1549, -7.2308, -7.2366, -7.2738, -7.3382, -5.9756, -7.4084, -7.4908, -7.5003, -5.6783, -3.7002, -4.0263, -5.9028, -5.0505, -4.4189, -5.4171, -5.1082, -4.8452, -2.9708, -3.0396, -4.8729, -5.3465, -3.1833, -4.2204, -3.5068, -4.9805, -3.5611, -4.3493, -3.4765, -4.2468, -4.1334, -3.9258, -5.1146, -5.2259, -4.0796, -4.2245, -4.2083, -4.5474, -4.3272, -4.4751, -4.8695, -4.7445, -4.7605, -4.9432, -4.95, -3.4523, -3.5107, -3.9399, -3.9556, -4.2934, -4.3512, -4.5529, -4.556, -4.5823, -4.6769, -4.7645, -4.8967, -4.9649, -4.9689, -5.0282, -5.0716, -5.2199, -5.3385, -5.4471, -5.4348, -5.4708, -5.5104, -5.5375, -5.5815, -5.668, -5.6794, -5.8003, -5.8576, -5.9367, -6.132, -3.5964, -4.6296, -4.7218, -4.7817, -5.1087, -3.744, -4.3016, -4.7301, -4.9059, -4.274, -3.9678, -4.239, -3.8597, -3.9653, -4.7195, -4.3737, -4.4218, -4.6046, -4.7551, -4.5272, -4.6249, -4.3858, -4.4301, -4.8349, -4.8481, -4.9548, -5.0339, -5.0904, -5.1388, -5.1823, -5.3295, -5.3391, -5.4071, -5.4973, -5.562, -5.6662, -5.7556, -5.7965, -5.7891, -5.8129, -5.8668, -5.8851, -5.9278, -5.9523, -5.9753, -5.9949, -6.004, -6.0273, -6.0301, -6.0925, -6.1118, -5.5902, -5.3187, -4.4956, -4.118, -4.8419, -4.9131, -5.333, -4.188, -4.7145, -4.305, -3.4586, -4.0658, -4.7583, -4.7505, -4.8759, -5.047, -3.9593, -5.041, -5.1488, -5.0969, -4.5262, -4.5457, -4.5869, -5.1914, -5.1578, -5.0944, -4.8183, -5.0022, -4.9848, -5.0854, -4.7069, -4.909, -5.1975, -5.2177, -5.293, -5.3395, -5.3575, -5.528, -5.5358, -5.5898, -5.7846, -5.8108, -5.808, -5.8283, -5.8507, -5.8684, -5.8918, -5.9245, -5.9556, -5.9638, -6.0724, -6.1123, -6.1187, -6.1182, -6.1584, -6.1657, -6.2118, -6.2435, -6.2438, -6.2452, -3.3778, -4.7717, -4.2339, -5.3986, -5.0593, -5.0426, -4.683, -4.7527, -5.5047, -5.5522, -5.3579, -5.311, -5.49, -5.1758, -4.9425, -4.6403, -4.2543, -4.5402, -5.1457, -4.3421, -4.4054, -4.98, -4.8966, -4.4627, -5.1679, -5.1022, -4.9491, -5.0986, -4.8585, -4.6544, -4.893, -5.2313, -4.0408, -4.2615, -4.3309, -4.3967, -4.4113, -4.4243, -4.599, -4.7915, -4.8995, -5.0204, -5.1023, -5.1442, -5.1488, -5.1941, -5.3591, -5.3637, -5.3692, -5.3831, -5.3847, -5.4105, -5.4226, -5.439, -5.4617, -5.4759, -5.5047, -5.5869, -5.6352, -5.6743, -5.7061, -5.7189, -4.9712, -5.3847, -5.6508, -2.9853, -3.3285, -3.3574, -3.4019, -3.4057, -3.9908, -3.9966, -4.1406, -4.3814, -4.4547, -4.4811, -4.4875, -4.4951, -4.5581, -4.6439, -4.7483, -4.7585, -4.8171, -4.8234, -4.9851, -5.0989, -5.1184, -5.1315, -5.16, -5.1808, -5.2006, -5.2189, -5.296, -5.3163, -5.4757, -2.7618, -2.613, -5.2937]}, \"token.table\": {\"Topic\": [2, 4, 1, 2, 1, 2, 5, 4, 1, 3, 4, 5, 4, 1, 4, 1, 6, 6, 1, 2, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 6, 3, 4, 6, 2, 6, 2, 4, 5, 4, 2, 5, 3, 1, 2, 3, 1, 4, 1, 1, 3, 1, 2, 3, 4, 1, 5, 4, 3, 4, 1, 4, 1, 2, 2, 3, 1, 6, 6, 4, 2, 2, 1, 1, 2, 4, 2, 4, 1, 2, 3, 5, 1, 2, 2, 4, 3, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 6, 6, 1, 3, 4, 6, 5, 1, 2, 4, 3, 2, 5, 2, 1, 3, 5, 3, 4, 1, 2, 4, 6, 5, 1, 3, 4, 1, 2, 4, 1, 2, 4, 1, 2, 1, 2, 3, 6, 3, 3, 4, 3, 1, 5, 1, 2, 4, 2, 1, 4, 1, 4, 3, 1, 3, 4, 1, 2, 3, 4, 3, 4, 2, 1, 1, 4, 5, 6, 5, 1, 3, 4, 1, 2, 3, 2, 6, 1, 2, 6, 2, 6, 5, 5, 6, 3, 4, 4, 3, 1, 4, 1, 1, 2, 5, 6, 1, 1, 4, 3, 1, 1, 4, 1, 3, 4, 6, 3, 3, 1, 2, 3, 4, 5, 3, 6, 1, 6, 6, 2, 3, 4, 1, 5, 6, 2, 3, 4, 3, 4, 5, 3, 4, 1, 2, 3, 4, 2, 6, 6, 1, 2, 3, 4, 2, 3, 4, 1, 1, 2, 4, 1, 2, 3, 3, 1, 2, 4, 3, 1, 2, 2, 5, 5, 5, 2, 2, 3, 4, 1, 2, 3, 4, 2, 2, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 4, 6, 3, 3, 5, 1, 1, 1, 2, 3, 6, 2, 1, 3, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 4, 5, 5, 6, 1, 3, 4, 1, 2, 3, 4, 2, 4, 3, 1, 2, 1, 2, 3, 5, 4, 1, 2, 3, 4, 1, 2, 6, 4, 6, 2, 5, 1, 2, 3, 3, 5, 4, 5, 2, 3, 4, 1, 3, 2, 3, 5, 5, 1, 5, 5, 1, 6, 1, 1, 3, 5, 2, 1, 2, 3, 4, 2, 2, 3, 1, 1, 2, 5, 2, 2, 3, 4, 4, 1, 4, 1, 4, 1, 3, 4, 5, 4, 6, 4, 1, 2, 3, 4, 1, 3, 3, 4, 3, 2, 2, 5, 2, 1, 2, 3, 4, 1, 3, 4, 2, 1, 4, 2, 4, 4, 3, 1, 1, 2, 3, 4, 1, 4, 3, 5, 2, 5, 1, 2, 4, 1, 3, 4, 3, 6], \"Freq\": [0.14108762773352587, 0.8566034540964071, 0.20758365800309608, 0.7922914118205818, 0.9728362352411198, 0.026259075758436397, 0.9922099587920555, 0.9985511640741415, 0.3302223315403583, 0.2136373679096588, 0.3882096171158371, 0.06775356525134893, 0.9982454263733227, 0.9952605953647102, 0.9966619530341398, 0.9997058191963896, 0.9926308842035088, 0.9979354988255008, 0.5063303390599512, 0.3079199667706966, 0.16082958894322474, 0.024919157415826277, 0.9976265177405295, 0.4177345031152405, 0.4485015849695901, 0.13385266538696394, 0.1288357307705189, 0.6193619352205684, 0.02270465747185374, 0.22915863587870985, 0.9997764244700653, 0.17922537219681392, 0.8194925639068112, 0.9987256942700918, 0.9969004564477377, 0.9989600453860146, 0.797611248599236, 0.20194837996448742, 0.9986196695379125, 0.996096516397765, 0.9975846619283315, 0.9979795892837863, 0.9982619254290832, 0.24128892075807631, 0.0037121372424319433, 0.7552136989880986, 0.9529324406823164, 0.04701969279682482, 0.9953308374328788, 0.4559994275043671, 0.5439844747408313, 0.14533784079843523, 0.1276137138717968, 0.714636797682062, 0.01276137138717968, 0.9486099864375456, 0.05103281572607049, 0.9958688770659038, 0.9995325340212985, 0.9975851330667818, 0.35633453886357125, 0.6439398639997475, 0.9969156053776049, 0.9998401823429649, 0.99787169503942, 0.9961206090756715, 0.9935949644227959, 0.9989547256000143, 0.9985365196971026, 0.9980418640332382, 0.9989567617581623, 0.9987518357710365, 0.9953860381714446, 0.4966150239901914, 0.12261465984881792, 0.3806697807858699, 0.8598878679611498, 0.14007223188507417, 0.7387841108185248, 0.15649031554743822, 0.10460094063153343, 0.995741658048732, 0.0757033880863639, 0.9241767545599368, 0.22128654826275232, 0.7779605212362386, 0.9980755223050055, 0.8075445459627362, 0.125291993863212, 0.06428695524876671, 0.0027027548753235254, 0.9978609720612052, 0.8694147691538687, 0.05828032887808303, 0.07185246026065031, 0.9942693869440068, 0.9987043780986541, 0.9971023259429008, 0.21547271052029354, 0.0019153129824026093, 0.2992676535004077, 0.4831376998110582, 0.9967320839627426, 0.9951995749304506, 0.9972242620738884, 0.12312130827011962, 0.23758564955249645, 0.6393330434651524, 0.997324679670195, 0.9269379999352995, 0.05648106180363778, 0.016484903205846432, 0.9958482652545052, 0.4052021314233749, 0.5939894881092656, 0.9990558265633018, 0.9985838839447339, 0.9989043813299685, 0.9970475191488215, 0.1207301698024793, 0.8785441587165033, 0.535660744150269, 0.4642969792856792, 0.996455250621742, 0.9926130619977644, 0.9969233697240112, 0.001652242928900844, 0.1641227976041505, 0.8343826790949262, 0.19223188686599374, 0.10148888437024514, 0.7044522562169956, 0.7568132272222144, 0.13932496819260207, 0.10384354295955274, 0.8238868748686009, 0.17537708915331623, 0.39484617890852175, 0.0052297507140201555, 0.5996780818743113, 0.9979220952321285, 0.9994221926451488, 0.1452344304180805, 0.852462961149603, 0.9987128064174229, 0.9980649996795329, 0.997629289523308, 0.8909608759075243, 0.10833348896443737, 0.0006565665997844689, 0.9986593362294486, 0.5074809104140329, 0.49235104476193753, 0.51326623826037, 0.48629524166388555, 0.9985137853402861, 0.3618185842379223, 0.6380237569941953, 0.996963707886044, 0.48053914863297775, 0.32712828532787847, 0.18038745955778346, 0.011857844506674344, 0.999319245918054, 0.9956828049418951, 0.9983270472585073, 0.9998442233996541, 0.12765544548313373, 0.5127493726905872, 0.35743524735277443, 0.996095194935518, 0.9928713735217148, 0.256003724929493, 0.03447614633720966, 0.7093283725123776, 0.5054084396004092, 0.23849930616948925, 0.25604655241919644, 0.3978100272623691, 0.602398041283016, 0.8031123646358135, 0.19688749984465775, 0.9947188821704599, 0.9991991428454853, 0.9936907003337099, 0.9957648277645469, 0.9935872763111425, 0.9985672903160511, 0.9978199977130029, 0.9975306803710037, 0.994414808126192, 0.9971302156043164, 0.2818798514365109, 0.7174399608595942, 0.9996993949732521, 0.9948572327016942, 0.49771046984051404, 0.43293992924483066, 0.06647502850609605, 0.9998612791850581, 0.6313994250752208, 0.3685570294583631, 0.9959382631581933, 0.997321639109663, 0.9949065346130083, 0.0041282428822116525, 0.7582798382299604, 0.0010656233819837833, 0.035165571605464845, 0.20548770882587286, 0.9983697359119038, 0.9968776632651672, 0.5189582729206075, 0.14060445818046016, 0.004857244918961351, 0.30805158564991725, 0.027353958227834978, 0.9993490466971343, 0.9961340780644515, 0.9982421805367643, 0.996862397373186, 0.9980581441601811, 0.9982708495897253, 0.8225749520547907, 0.17704757130078927, 0.9963065778438702, 0.999320406224471, 0.9981424499939825, 0.15691049133337973, 0.7104673970983533, 0.1323542075438057, 0.20359910059286632, 0.7950060118388114, 0.9955017023948434, 0.09779886255519393, 0.901583264180694, 0.26981173559505917, 0.04364601605214192, 0.2440209079278844, 0.4424118899830749, 0.998967587670658, 0.9985358330457439, 0.9954417981220943, 0.22467596509440632, 0.21968316587008618, 0.3827812738645441, 0.1725289509737293, 0.08793717577877047, 0.8842571564420809, 0.027683925708131447, 0.99202917429353, 0.40078950229174426, 0.5964941635171811, 0.0025582308656919846, 0.7009513345212809, 0.23877424166512898, 0.06021124973276768, 0.9982608709670828, 0.5559359800654978, 0.4328564879056182, 0.011084081845542637, 0.9955224115697687, 0.9434744760588792, 0.056471006245697834, 0.9990116401604101, 0.9935609892769368, 0.9982583998448493, 0.9975797882653394, 0.9990671814731787, 0.999584854090327, 0.23980377503802955, 0.7591334228197746, 0.5352369230617388, 0.010990491233300589, 0.10331061759302554, 0.3505966703422888, 0.9996132263986607, 0.9991698554510128, 0.578321553462495, 0.16835753446288815, 0.09760134970570622, 0.15551020552323722, 0.9988991329342056, 0.9981099326431822, 0.6833926042709682, 0.2316915097101003, 0.08469395523016271, 0.00024337343456943308, 0.26471312967440885, 0.04198622147403766, 0.6070008018818016, 0.0859717868277914, 0.9994865304318716, 0.9975800261256653, 0.9959456421448818, 0.9976542817121082, 0.9985189645341457, 0.9901630679344546, 0.009430124456518616, 0.9984251675519042, 0.9964323020466372, 0.259391645847245, 0.09566916215658845, 0.6440408545180646, 0.9942511651814314, 0.9993250243405732, 0.998855933174658, 0.9979481952954269, 0.3347435095853963, 0.06598640024681324, 0.5897534522058933, 0.008935658366755958, 0.7865976969649132, 0.2132819972461296, 0.9976648570795856, 0.7488768769920028, 0.19070974706448884, 0.0576889051852314, 0.0027289581110725527, 0.9975556965231539, 0.9970057124139228, 0.9952338062309004, 0.99898091971116, 0.37888504805523443, 0.620381598955305, 0.9988931944418682, 0.2677731263299607, 0.06920905418989753, 0.04861112139528517, 0.6146423145912329, 0.999015961668576, 0.998645995804451, 0.9958342059647981, 0.5438182994547506, 0.45591159216735083, 0.1783822082734402, 0.2589972447047065, 0.5548715805428645, 0.006860854164363085, 0.9958593876832573, 0.7300976485878886, 0.1326432063728599, 0.011840286214223924, 0.12528302845590988, 0.9470985679905104, 0.052758652643495815, 0.9978382749800935, 0.9961429734429789, 0.999198165276426, 0.9995772173607097, 0.9954063234647821, 0.5242958624437547, 0.03020427436065798, 0.44551304681970516, 0.9986860155731003, 0.998540190944917, 0.9981675400947032, 0.992608808776222, 0.9992205624188674, 0.9990811750276252, 0.9979973780834529, 0.1762908019410178, 0.8239275374927568, 0.19280467707863913, 0.8065662324456404, 0.9954255685672033, 0.9948191148603047, 0.9980616378112647, 0.9932908613292496, 0.9958920842365026, 0.9987062596153071, 0.9931195551484315, 0.9956437759464205, 0.9946677980546325, 0.9972253749841676, 0.9957627187892729, 0.99991517837011, 0.814772901575071, 0.0867587425687036, 0.042932736830973664, 0.0555501601389061, 0.9996648630833073, 0.7934075914012798, 0.20611868903120598, 0.9991297707383666, 0.9032827476931983, 0.08750551618277859, 0.009274778212921232, 0.9986757761918601, 0.31257472890321136, 0.15030507298934326, 0.536910658738052, 0.9989271195094314, 0.8605882169573148, 0.13903163423236783, 0.9355200848256324, 0.06410648664891093, 0.040534511071108545, 0.6370967718350321, 0.3189889784291586, 0.0035247400931398736, 0.9980511524249192, 0.9975969373899058, 0.9977195776417368, 0.5324094469955819, 0.004487337927082247, 0.10426461654102867, 0.3587230731120455, 0.9985271626799606, 0.997680485958224, 0.9963012810265378, 0.9994092548984725, 0.9983460697203941, 0.9993132427158028, 0.9996327819120636, 0.9946119838996546, 0.9994290261757202, 0.1254197122227897, 0.002684079444456589, 0.00195205777778661, 0.8698857472261581, 0.07309580433402131, 0.647132579654409, 0.27897114314635657, 0.9997414222241612, 0.9918798752920995, 0.007135826440950356, 0.9999092114456648, 0.9959578267500039, 0.9978728571219491, 0.9991349578954416, 0.9989038324951448, 0.48684648533197017, 0.3168397725631944, 0.1288535014522449, 0.06732345734791709, 0.180208005304607, 0.8175752661714276, 0.9661316579578006, 0.03331488475716554, 0.9989810083715821, 0.9970304378174137, 0.8390515432633848, 0.05813036835680967, 0.10200234447515659, 0.18393743376870664, 0.610195172775368, 0.20528170935961457, 0.9983725115092328, 0.9968230022854089], \"Term\": [\"able\", \"able\", \"access\", \"access\", \"accommodate\", \"accommodate\", \"accurate\", \"air\", \"airbnb\", \"airbnb\", \"airbnb\", \"airbnb\", \"airport\", \"alex\", \"allow\", \"amazing\", \"anna\", \"answer\", \"apartment\", \"apartment\", \"apartment\", \"apartment\", \"appartement\", \"area\", \"area\", \"area\", \"around\", \"around\", \"around\", \"around\", \"arrival\", \"arrive\", \"arrive\", \"attentive\", \"attraction\", \"automated\", \"away\", \"away\", \"bad\", \"bag\", \"bar\", \"basic\", \"bath\", \"bathroom\", \"bathroom\", \"bathroom\", \"beautiful\", \"beautiful\", \"beautifully\", \"bed\", \"bed\", \"bedroom\", \"bedroom\", \"bedroom\", \"bedroom\", \"best\", \"best\", \"beyond\", \"bit\", \"booking\", \"breakfast\", \"breakfast\", \"brilliant\", \"bus\", \"cafe\", \"call\", \"calm\", \"cancel\", \"cant\", \"care\", \"center\", \"centre\", \"chat\", \"check\", \"check\", \"check\", \"city\", \"city\", \"clean\", \"clean\", \"clean\", \"cleaning\", \"close\", \"close\", \"coffee\", \"coffee\", \"cold\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"communicate\", \"communication\", \"communication\", \"communication\", \"communicative\", \"cook\", \"cool\", \"could\", \"could\", \"could\", \"could\", \"cross\", \"daughter\", \"david\", \"day\", \"day\", \"day\", \"de\", \"definitely\", \"definitely\", \"definitely\", \"described\", \"despite\", \"despite\", \"distance\", \"dog\", \"door\", \"downstairs\", \"early\", \"early\", \"easy\", \"easy\", \"else\", \"enjoyed\", \"equipment\", \"even\", \"even\", \"even\", \"every\", \"every\", \"every\", \"everything\", \"everything\", \"everything\", \"excellent\", \"excellent\", \"expect\", \"expect\", \"expect\", \"expectation\", \"explore\", \"extra\", \"extra\", \"fabulous\", \"facility\", \"fact\", \"fantastic\", \"fantastic\", \"fantastic\", \"far\", \"feel\", \"feel\", \"felt\", \"felt\", \"fine\", \"first\", \"first\", \"fix\", \"flat\", \"flat\", \"flat\", \"flat\", \"floor\", \"fresh\", \"friend\", \"friendly\", \"full\", \"full\", \"full\", \"gem\", \"general\", \"give\", \"give\", \"give\", \"good\", \"good\", \"good\", \"gorgeous\", \"gorgeous\", \"great\", \"great\", \"greet\", \"grocery\", \"ground\", \"half\", \"hang\", \"happy\", \"hear\", \"heart\", \"heat\", \"heating\", \"help\", \"help\", \"helpful\", \"hesitate\", \"high\", \"high\", \"high\", \"highly\", \"home\", \"home\", \"homely\", \"hospitable\", \"hospitality\", \"hospitality\", \"host\", \"host\", \"host\", \"host\", \"hot\", \"hotel\", \"house\", \"house\", \"house\", \"house\", \"house\", \"however\", \"hyde\", \"ideal\", \"immediately\", \"incredibly\", \"instruction\", \"issue\", \"issue\", \"john\", \"keep\", \"king\", \"kitchen\", \"kitchen\", \"kitchen\", \"late\", \"late\", \"later\", \"leave\", \"leave\", \"like\", \"like\", \"like\", \"like\", \"line\", \"link\", \"literally\", \"little\", \"little\", \"little\", \"little\", \"living\", \"living\", \"living\", \"load\", \"locate\", \"locate\", \"locate\", \"location\", \"location\", \"location\", \"lock\", \"london\", \"london\", \"london\", \"loud\", \"lovely\", \"lovely\", \"main\", \"maintain\", \"market\", \"maybe\", \"min\", \"minute\", \"morning\", \"morning\", \"much\", \"much\", \"much\", \"much\", \"near\", \"nearby\", \"need\", \"need\", \"need\", \"need\", \"neighbourhood\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"noise\", \"noisy\", \"note\", \"nothing\", \"ok\", \"open\", \"open\", \"option\", \"outstanding\", \"overall\", \"overall\", \"overall\", \"oxford\", \"park\", \"parking\", \"pay\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"phone\", \"place\", \"place\", \"place\", \"place\", \"pleasure\", \"plus\", \"polite\", \"posting\", \"price\", \"price\", \"property\", \"provide\", \"provide\", \"provide\", \"provide\", \"pub\", \"put\", \"quality\", \"quiet\", \"quiet\", \"quite\", \"quite\", \"quite\", \"quite\", \"real\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommend\", \"recommendation\", \"rent\", \"reservation\", \"restaurant\", \"review\", \"room\", \"room\", \"room\", \"second\", \"seem\", \"send\", \"shampoo\", \"shop\", \"shower\", \"situate\", \"sleep\", \"sleep\", \"small\", \"small\", \"smell\", \"soap\", \"soon\", \"sort\", \"sound\", \"sparkle\", \"special\", \"spotless\", \"spotlessly\", \"stair\", \"standard\", \"station\", \"stay\", \"stay\", \"stay\", \"stay\", \"stop\", \"street\", \"street\", \"stylish\", \"super\", \"super\", \"super\", \"supermarket\", \"take\", \"take\", \"take\", \"tea\", \"thank\", \"thank\", \"thanks\", \"thanks\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"thoroughly\", \"thoughtful\", \"time\", \"time\", \"time\", \"time\", \"tip\", \"toilet\", \"totally\", \"touch\", \"towel\", \"train\", \"tube\", \"uncomfortable\", \"underground\", \"us\", \"us\", \"us\", \"us\", \"use\", \"use\", \"use\", \"value\", \"view\", \"view\", \"walk\", \"wall\", \"wasnt\", \"water\", \"welcoming\", \"well\", \"well\", \"well\", \"well\", \"wifi\", \"wifi\", \"window\", \"window\", \"within\", \"without\", \"wonderful\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"worth\", \"youre\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 6, 5, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el353951121541274804187150278\", ldavis_el353951121541274804187150278_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el353951121541274804187150278\", ldavis_el353951121541274804187150278_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el353951121541274804187150278\", ldavis_el353951121541274804187150278_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "0       18.669203   90.327049       1        1  39.086114\n",
       "3       56.526554 -108.247726       2        1  21.757651\n",
       "5      -90.819992   30.150517       3        1  15.440458\n",
       "4      109.734451    4.792168       4        1  14.344205\n",
       "1      -67.422646  -92.575256       5        1   5.038608\n",
       "2        5.337548  -15.110545       6        1   4.332964, topic_info=      Category          Freq            Term         Total  loglift  logprob\n",
       "term                                                                        \n",
       "7928   Default  11261.000000            host  11261.000000  30.0000  30.0000\n",
       "7229   Default  16964.000000           great  16964.000000  29.0000  29.0000\n",
       "4371   Default   3118.000000             day   3118.000000  28.0000  28.0000\n",
       "18322  Default   5020.000000            walk   5020.000000  27.0000  27.0000\n",
       "16082  Default   4735.000000         station   4735.000000  26.0000  26.0000\n",
       "17907  Default   4098.000000              us   4098.000000  25.0000  25.0000\n",
       "14498  Default   7945.000000            room   7945.000000  24.0000  24.0000\n",
       "3374   Default   4702.000000           close   4702.000000  23.0000  23.0000\n",
       "13878  Default   7430.000000       recommend   7430.000000  22.0000  22.0000\n",
       "1378   Default   1595.000000         arrival   1595.000000  21.0000  21.0000\n",
       "17497  Default   3083.000000            tube   3083.000000  20.0000  20.0000\n",
       "10955  Default   3035.000000          minute   3035.000000  19.0000  19.0000\n",
       "10009  Default   8661.000000          london   8661.000000  18.0000  18.0000\n",
       "12874  Default  15756.000000           place  15756.000000  17.0000  17.0000\n",
       "1914   Default   3546.000000             bed   3546.000000  16.0000  16.0000\n",
       "16101  Default  17911.000000            stay  17911.000000  15.0000  15.0000\n",
       "9951   Default  12555.000000        location  12555.000000  14.0000  14.0000\n",
       "10107  Default   5383.000000          lovely   5383.000000  13.0000  13.0000\n",
       "2718   Default   1132.000000          cancel   1132.000000  12.0000  12.0000\n",
       "14177  Default   1099.000000     reservation   1099.000000  11.0000  11.0000\n",
       "1842   Default   2424.000000        bathroom   2424.000000  10.0000  10.0000\n",
       "13106  Default   1052.000000         posting   1052.000000   9.0000   9.0000\n",
       "7129   Default   8377.000000            good   8377.000000   8.0000   8.0000\n",
       "1600   Default   1048.000000       automated   1048.000000   7.0000   7.0000\n",
       "2568   Default   2165.000000             bus   2165.000000   6.0000   6.0000\n",
       "14243  Default   2043.000000      restaurant   2043.000000   5.0000   5.0000\n",
       "3307   Default  10946.000000           clean  10946.000000   4.0000   4.0000\n",
       "7841   Default   3462.000000            home   3462.000000   3.0000   3.0000\n",
       "5288   Default   4624.000000            easy   4624.000000   2.0000   2.0000\n",
       "5851   Default   1815.000000            even   1815.000000   1.0000   1.0000\n",
       "...        ...           ...             ...           ...      ...      ...\n",
       "13106   Topic6   1051.247964         posting   1052.072146   3.1381  -3.4019\n",
       "1600    Topic6   1047.265823       automated   1048.089966   3.1381  -3.4057\n",
       "1149    Topic6    583.372478          answer    584.206094   3.1375  -3.9908\n",
       "7498    Topic6    579.999293           happy    580.832164   3.1375  -3.9966\n",
       "3562    Topic6    502.244563     communicate    503.076094   3.1373  -4.1406\n",
       "9854    Topic6    394.748191            link    395.579194   3.1368  -4.3814\n",
       "9296    Topic6    366.853534            king    367.682990   3.1367  -4.4547\n",
       "18933   Topic6    357.304231           youre    358.137803   3.1366  -4.4811\n",
       "11806   Topic6    355.000598         nothing    355.834688   3.1366  -4.4875\n",
       "4103    Topic6    352.323910           cross    353.154078   3.1366  -4.4951\n",
       "8272    Topic6    330.811965      incredibly    331.644005   3.1364  -4.5581\n",
       "2741    Topic6    303.613607            cant    304.445550   3.1362  -4.6439\n",
       "1543    Topic6    273.519552       attentive    274.349605   3.1359  -4.7483\n",
       "6001    Topic6    270.733662     expectation    271.564285   3.1359  -4.7585\n",
       "9882    Topic6    255.332679       literally    256.167664   3.1357  -4.8171\n",
       "13881   Topic6    253.717971  recommendation    254.550268   3.1356  -4.8234\n",
       "8167    Topic6    215.845139     immediately    216.679855   3.1351  -4.9851\n",
       "17016   Topic6    192.633953      thoroughly    193.464908   3.1346  -5.0989\n",
       "8056    Topic6    188.898134            hyde    189.733495   3.1345  -5.1184\n",
       "15871   Topic6    186.457052         special    187.288629   3.1345  -5.1315\n",
       "12303   Topic6    181.214945          oxford    182.046556   3.1343  -5.1600\n",
       "1103    Topic6    177.483840            anna    178.314017   3.1343  -5.1808\n",
       "4348    Topic6    174.005871        daughter    174.839303   3.1341  -5.2006\n",
       "6914    Topic6    170.839808             gem    171.670339   3.1341  -5.2189\n",
       "7285    Topic6    158.165999          ground    159.003199   3.1336  -5.2960\n",
       "7250    Topic6    154.987980           greet    155.822919   3.1335  -5.3163\n",
       "5631    Topic6    132.152752         enjoyed    132.982332   3.1327  -5.4757\n",
       "4371    Topic6   1994.004437             day   3118.875241   2.6916  -2.7618\n",
       "7928    Topic6   2313.824660            host  11261.014166   1.5565  -2.6130\n",
       "7152    Topic6    158.531045        gorgeous    263.945081   2.6291  -5.2937\n",
       "\n",
       "[335 rows x 6 columns], token_table=       Topic      Freq         Term\n",
       "term                               \n",
       "329        2  0.141088         able\n",
       "329        4  0.856603         able\n",
       "385        1  0.207584       access\n",
       "385        2  0.792291       access\n",
       "401        1  0.972836  accommodate\n",
       "401        2  0.026259  accommodate\n",
       "434        5  0.992210     accurate\n",
       "671        4  0.998551          air\n",
       "675        1  0.330222       airbnb\n",
       "675        3  0.213637       airbnb\n",
       "675        4  0.388210       airbnb\n",
       "675        5  0.067754       airbnb\n",
       "690        4  0.998245      airport\n",
       "779        1  0.995261         alex\n",
       "841        4  0.996662        allow\n",
       "928        1  0.999706      amazing\n",
       "1103       6  0.992631         anna\n",
       "1149       6  0.997935       answer\n",
       "1206       1  0.506330    apartment\n",
       "1206       2  0.307920    apartment\n",
       "1206       3  0.160830    apartment\n",
       "1206       4  0.024919    apartment\n",
       "1230       1  0.997627  appartement\n",
       "1315       1  0.417735         area\n",
       "1315       2  0.448502         area\n",
       "1315       3  0.133853         area\n",
       "1367       1  0.128836       around\n",
       "1367       2  0.619362       around\n",
       "1367       3  0.022705       around\n",
       "1367       4  0.229159       around\n",
       "...      ...       ...          ...\n",
       "17907      4  0.869886           us\n",
       "17917      1  0.073096          use\n",
       "17917      3  0.647133          use\n",
       "17917      4  0.278971          use\n",
       "17984      2  0.999741        value\n",
       "18141      1  0.991880         view\n",
       "18141      4  0.007136         view\n",
       "18322      2  0.999909         walk\n",
       "18333      4  0.995958         wall\n",
       "18400      4  0.997873        wasnt\n",
       "18412      3  0.999135        water\n",
       "18485      1  0.998904    welcoming\n",
       "18490      1  0.486846         well\n",
       "18490      2  0.316840         well\n",
       "18490      3  0.128854         well\n",
       "18490      4  0.067323         well\n",
       "18606      1  0.180208         wifi\n",
       "18606      4  0.817575         wifi\n",
       "18632      3  0.966132       window\n",
       "18632      5  0.033315       window\n",
       "18665      2  0.998981       within\n",
       "18668      5  0.997030      without\n",
       "18693      1  0.839052    wonderful\n",
       "18693      2  0.058130    wonderful\n",
       "18693      4  0.102002    wonderful\n",
       "18723      1  0.183937         work\n",
       "18723      3  0.610195         work\n",
       "18723      4  0.205282         work\n",
       "18748      3  0.998373        worth\n",
       "18933      6  0.996823        youre\n",
       "\n",
       "[450 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 6, 5, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "visualization_panel = pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')\n",
    "visualization_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    verbose = False):\n",
    "    \n",
    "    #pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    #analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    #get binary sentiment\n",
    "    binary_sentiment = 'positive' if scores['compound'] >= 0.65\\\n",
    "                                   else 'neutral' if scores['compound'] >= 0.1\\\n",
    "                                                    else'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        #display sentiment \n",
    "        sentiment_frame = pd.DataFrame([[binary_sentiment, round(scores['compound'], 2)]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Binary Sentiment ', 'Polarity Score']], \n",
    "                                                              labels=[[0,0],[0,1]]))\n",
    "        print(sentiment_frame.to_string(index=False))\n",
    "    \n",
    "    return binary_sentiment,scores['compound']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>binary sentiment</th>\n",
       "      <th>raw score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super convenient and the flat has everything y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paulo's place was nice and clean. The area is ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The place is exactly as described in the Ad, t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was the second time we have stopped with ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the moment we entered Elsa &amp;Dom’s house w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews binary sentiment  \\\n",
       "0  Super convenient and the flat has everything y...         positive   \n",
       "1  Paulo's place was nice and clean. The area is ...         positive   \n",
       "2  The place is exactly as described in the Ad, t...          neutral   \n",
       "3  This was the second time we have stopped with ...         positive   \n",
       "4  From the moment we entered Elsa &Dom’s house w...         positive   \n",
       "\n",
       "   raw score  \n",
       "0     0.9136  \n",
       "1     0.9646  \n",
       "2     0.6239  \n",
       "3     0.8977  \n",
       "4     0.9122  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore')\n",
    "predicted_sentiment_test = pd.DataFrame([analyze_sentiment_vader_lexicon(review)\n",
    "                     for review in reviews_f],columns = ['binary sentiment','raw score'])\n",
    "\n",
    "sentiment = pd.concat([pd.DataFrame(reviews_f),predicted_sentiment_test],axis = 1)\n",
    "sentiment.columns = [\"reviews\",'binary sentiment','raw score']\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.900e+01, 2.600e+01, 2.900e+01, 2.600e+01, 3.100e+01, 2.700e+01,\n",
       "        2.400e+01, 1.600e+01, 2.800e+01, 2.700e+01, 2.700e+01, 2.200e+01,\n",
       "        1.100e+01, 2.200e+01, 2.000e+01, 2.200e+01, 1.300e+01, 1.900e+01,\n",
       "        1.700e+01, 1.500e+01, 2.800e+01, 2.400e+01, 1.700e+01, 3.200e+01,\n",
       "        2.100e+01, 2.500e+01, 1.900e+01, 1.500e+01, 3.500e+01, 3.000e+01,\n",
       "        1.500e+01, 1.900e+01, 1.600e+01, 2.600e+01, 2.000e+01, 2.000e+01,\n",
       "        2.300e+01, 1.700e+01, 1.600e+01, 1.511e+03, 5.000e+00, 1.800e+01,\n",
       "        2.900e+01, 2.900e+01, 2.500e+01, 2.900e+01, 4.200e+01, 4.800e+01,\n",
       "        6.000e+01, 8.900e+01, 8.100e+01, 5.700e+01, 5.100e+01, 1.020e+02,\n",
       "        1.330e+02, 5.500e+01, 3.790e+02, 3.410e+02, 1.500e+02, 4.450e+02,\n",
       "        1.550e+02, 1.790e+02, 4.170e+02, 3.440e+02, 2.560e+02, 7.710e+02,\n",
       "        4.510e+02, 4.700e+02, 5.490e+02, 6.370e+02, 9.020e+02, 1.239e+03,\n",
       "        1.334e+03, 1.725e+03, 1.881e+03, 2.633e+03, 3.470e+03, 4.500e+03,\n",
       "        5.740e+03, 4.157e+03]),\n",
       " array([-9.9830000e-01, -9.7332875e-01, -9.4835750e-01, -9.2338625e-01,\n",
       "        -8.9841500e-01, -8.7344375e-01, -8.4847250e-01, -8.2350125e-01,\n",
       "        -7.9853000e-01, -7.7355875e-01, -7.4858750e-01, -7.2361625e-01,\n",
       "        -6.9864500e-01, -6.7367375e-01, -6.4870250e-01, -6.2373125e-01,\n",
       "        -5.9876000e-01, -5.7378875e-01, -5.4881750e-01, -5.2384625e-01,\n",
       "        -4.9887500e-01, -4.7390375e-01, -4.4893250e-01, -4.2396125e-01,\n",
       "        -3.9899000e-01, -3.7401875e-01, -3.4904750e-01, -3.2407625e-01,\n",
       "        -2.9910500e-01, -2.7413375e-01, -2.4916250e-01, -2.2419125e-01,\n",
       "        -1.9922000e-01, -1.7424875e-01, -1.4927750e-01, -1.2430625e-01,\n",
       "        -9.9335000e-02, -7.4363750e-02, -4.9392500e-02, -2.4421250e-02,\n",
       "         5.5000000e-04,  2.5521250e-02,  5.0492500e-02,  7.5463750e-02,\n",
       "         1.0043500e-01,  1.2540625e-01,  1.5037750e-01,  1.7534875e-01,\n",
       "         2.0032000e-01,  2.2529125e-01,  2.5026250e-01,  2.7523375e-01,\n",
       "         3.0020500e-01,  3.2517625e-01,  3.5014750e-01,  3.7511875e-01,\n",
       "         4.0009000e-01,  4.2506125e-01,  4.5003250e-01,  4.7500375e-01,\n",
       "         4.9997500e-01,  5.2494625e-01,  5.4991750e-01,  5.7488875e-01,\n",
       "         5.9986000e-01,  6.2483125e-01,  6.4980250e-01,  6.7477375e-01,\n",
       "         6.9974500e-01,  7.2471625e-01,  7.4968750e-01,  7.7465875e-01,\n",
       "         7.9963000e-01,  8.2460125e-01,  8.4957250e-01,  8.7454375e-01,\n",
       "         8.9951500e-01,  9.2448625e-01,  9.4945750e-01,  9.7442875e-01,\n",
       "         9.9940000e-01]),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentiment.loc[sentiment[\"binary sentiment\"] == \"negative\"]\n",
    "plt.hist(sentiment[\"raw score\"],bins = 80, histtype=\"stepfilled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration on Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40931372549019607"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = sentiment.loc[sentiment[\"binary sentiment\"] == \"negative\"]\n",
    "cancellation = 0\n",
    "for review in negative[\"reviews\"]:\n",
    "    cancellation += \"The host canceled this reservation\" in review\n",
    "cancellation/len(negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.183526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.304465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw score\n",
       "count  2448.000000\n",
       "mean     -0.183526\n",
       "std       0.304465\n",
       "min      -0.998300\n",
       "25%      -0.318200\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       0.099200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>room</td>\n",
       "      <td>host</td>\n",
       "      <td>place</td>\n",
       "      <td>work</td>\n",
       "      <td>flat</td>\n",
       "      <td>bed</td>\n",
       "      <td>shower</td>\n",
       "      <td>que</td>\n",
       "      <td>night</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>flat</td>\n",
       "      <td>room</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>bed</td>\n",
       "      <td>place</td>\n",
       "      <td>stay</td>\n",
       "      <td>host</td>\n",
       "      <td>door</td>\n",
       "      <td>dirty</td>\n",
       "      <td>shower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>stay</td>\n",
       "      <td>room</td>\n",
       "      <td>apartment</td>\n",
       "      <td>host</td>\n",
       "      <td>us</td>\n",
       "      <td>place</td>\n",
       "      <td>bad</td>\n",
       "      <td>check</td>\n",
       "      <td>day</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_3</th>\n",
       "      <td>tim</td>\n",
       "      <td>tatiana</td>\n",
       "      <td>hall</td>\n",
       "      <td>significant</td>\n",
       "      <td>active</td>\n",
       "      <td>exterior</td>\n",
       "      <td>nightlife</td>\n",
       "      <td>intersection</td>\n",
       "      <td>reduction</td>\n",
       "      <td>interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_0   word_1     word_2       word_3  word_4    word_5     word_6  \\\n",
       "Topic_0   room     host      place         work    flat       bed     shower   \n",
       "Topic_1   flat     room   bathroom          bed   place      stay       host   \n",
       "Topic_2   stay     room  apartment         host      us     place        bad   \n",
       "Topic_3    tim  tatiana       hall  significant  active  exterior  nightlife   \n",
       "\n",
       "               word_7     word_8    word_9  \n",
       "Topic_0           que      night        us  \n",
       "Topic_1          door      dirty    shower  \n",
       "Topic_2         check        day      time  \n",
       "Topic_3  intersection  reduction  interior  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative[negative[\"raw score\"]< -0.1]\n",
    "normalized_neg = normalize_corpus(negative[\"reviews\"])\n",
    "bow_vectorizer_neg = CountVectorizer()\n",
    "bow_neg = bow_vectorizer_neg.fit_transform(normalized_neg)\n",
    "bow_feature_names_neg = bow_vectorizer_neg.get_feature_names()\n",
    "no_topics_news = 6\n",
    "lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_neg)\n",
    "no_top_words_news = 10\n",
    "topic_words = get_topic_words(vectorizer = bow_vectorizer_neg, \n",
    "                              lda_model = lda_news, \n",
    "                              n_words = no_top_words_news)\n",
    "pd.DataFrame(topic_words, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_top_words_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_words))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration on Neutral Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>quick</td>\n",
       "      <td>comfortable</td>\n",
       "      <td>ok</td>\n",
       "      <td>thank</td>\n",
       "      <td>response</td>\n",
       "      <td>bad</td>\n",
       "      <td>night</td>\n",
       "      <td>spot</td>\n",
       "      <td>worth</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>experience</td>\n",
       "      <td>host</td>\n",
       "      <td>airbnb</td>\n",
       "      <td>thanks</td>\n",
       "      <td>describe</td>\n",
       "      <td>outside</td>\n",
       "      <td>exactly</td>\n",
       "      <td>first</td>\n",
       "      <td>apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>apartment</td>\n",
       "      <td>room</td>\n",
       "      <td>clean</td>\n",
       "      <td>host</td>\n",
       "      <td>location</td>\n",
       "      <td>need</td>\n",
       "      <td>flat</td>\n",
       "      <td>everything</td>\n",
       "      <td>stay</td>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_3</th>\n",
       "      <td>room</td>\n",
       "      <td>bed</td>\n",
       "      <td>like</td>\n",
       "      <td>kind</td>\n",
       "      <td>house</td>\n",
       "      <td>hospitality</td>\n",
       "      <td>nothing</td>\n",
       "      <td>property</td>\n",
       "      <td>area</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_4</th>\n",
       "      <td>location</td>\n",
       "      <td>good</td>\n",
       "      <td>close</td>\n",
       "      <td>great</td>\n",
       "      <td>price</td>\n",
       "      <td>convenient</td>\n",
       "      <td>station</td>\n",
       "      <td>bus</td>\n",
       "      <td>stop</td>\n",
       "      <td>near</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_5</th>\n",
       "      <td>place</td>\n",
       "      <td>stay</td>\n",
       "      <td>london</td>\n",
       "      <td>nice</td>\n",
       "      <td>great</td>\n",
       "      <td>location</td>\n",
       "      <td>walk</td>\n",
       "      <td>good</td>\n",
       "      <td>station</td>\n",
       "      <td>close</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word_0       word_1  word_2  word_3    word_4       word_5  \\\n",
       "Topic_0      quick  comfortable      ok   thank  response          bad   \n",
       "Topic_1  excellent   experience    host  airbnb    thanks     describe   \n",
       "Topic_2  apartment         room   clean    host  location         need   \n",
       "Topic_3       room          bed    like    kind     house  hospitality   \n",
       "Topic_4   location         good   close   great     price   convenient   \n",
       "Topic_5      place         stay  london    nice     great     location   \n",
       "\n",
       "          word_6      word_7   word_8     word_9  \n",
       "Topic_0    night        spot    worth       much  \n",
       "Topic_1  outside     exactly    first  apartment  \n",
       "Topic_2     flat  everything     stay      check  \n",
       "Topic_3  nothing    property     area      night  \n",
       "Topic_4  station         bus     stop       near  \n",
       "Topic_5     walk        good  station      close  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral = sentiment.loc[sentiment[\"binary sentiment\"] == \"neutral\"]\n",
    "normalized_neu = normalize_corpus(neutral[\"reviews\"])\n",
    "bow_vectorizer_neu = CountVectorizer()\n",
    "bow_neu = bow_vectorizer_neu.fit_transform(normalized_neu)\n",
    "bow_feature_names_neu = bow_vectorizer_neu.get_feature_names()\n",
    "no_topics_news = 6\n",
    "lda_news = LatentDirichletAllocation(n_components=no_topics_news, max_iter=100,random_state = 42).fit(bow_neu)\n",
    "no_top_words_news = 10\n",
    "topic_words = get_topic_words(vectorizer = bow_vectorizer_neu, \n",
    "                              lda_model = lda_news, \n",
    "                              n_words = no_top_words_news)\n",
    "pd.DataFrame(topic_words, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_top_words_news)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.490355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.649400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw score\n",
       "count  4212.000000\n",
       "mean      0.490355\n",
       "std       0.128313\n",
       "min       0.100100\n",
       "25%       0.421500\n",
       "50%       0.507000\n",
       "75%       0.599400\n",
       "max       0.649400"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
